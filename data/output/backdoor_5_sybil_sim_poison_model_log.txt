
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.9070995 1.        0.
 0.        0.       ]
wv_mn shape (30,)
[1.         0.5304135  1.         0.52985818 0.65236216 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.52985818 1.         0.74935023 1.         1.         1.
 1.         0.         0.         1.         0.61351405 1.        ]
wv_ed shape (30,)
[0.93807617 0.41634061 1.         0.53185196 0.52086292 1.
 1.         1.         0.68637688 1.         1.         0.54026368
 1.         1.         1.         1.         1.         1.
 0.41634061 1.         0.42150762 1.         1.         1.
 1.         0.         0.         1.         0.         1.        ]
wv_lg shape (30,)
[0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.
 1. 0. 1. 0. 0. 1.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.52288731 0.9534633  0.
 0.32735013 1.         0.         1.         0.         0.27729661
 0.         0.         0.         0.61644293 1.         0.17029472
 0.         0.         0.70071168 0.         0.         0.06578618]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         1.         1.         1.
 0.         1.         1.         1.         0.18583915 1.
 0.03523207 0.32848113 1.         1.         0.         0.
 0.         0.         0.         1.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         1.         0.93807617 0.         0.51319942
  1.         0.         0.        ]
 [0.         0.         0.5304135  0.41634061 1.         0.51319942
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.         0.51319942
  1.         0.         0.        ]
 [0.         0.         0.52985818 0.53185196 1.         0.51319942
  1.         0.         0.        ]
 [0.         0.         0.65236216 0.52086292 0.         0.51319942
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.         0.51319942
  1.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  1.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  1.         1.         1.        ]
 [0.         0.         1.         0.68637688 1.         0.51319942
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  0.52288731 1.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  0.9534633  1.         1.        ]
 [1.         0.         1.         0.54026368 1.         0.51319942
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.         0.51319942
  0.32735013 0.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.         0.51319942
  0.         0.18583915 1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  0.27729661 1.         1.        ]
 [0.         0.         0.52985818 0.41634061 1.         0.51319942
  0.         0.03523207 1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  0.         0.32848113 1.        ]
 [0.         0.         0.74935023 0.42150762 0.         0.51319942
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  0.61644293 1.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  1.         0.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  0.17029472 0.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  0.         0.         1.        ]
 [0.         0.9070995  0.         0.         0.         0.51319942
  0.         0.         1.        ]
 [0.         1.         0.         0.         1.         0.51319942
  0.70071168 0.         1.        ]
 [0.         0.         1.         1.         0.         0.51319942
  0.         1.         1.        ]
 [0.         0.         0.61351405 0.         0.         0.51319942
  0.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.51319942
  0.06578618 0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.        0.        0.        0.        0.        0.        1.
 1.        0.        0.        1.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.0668861 0.        0.        0.
 1.        0.       ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.15432371
 0.         0.         0.         0.0203009  0.         0.
 0.         0.         0.         1.         0.2563228  0.
 0.         0.         0.732977   0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         1.         1.         0.
 0.         0.         0.         0.         0.59837597 1.
 0.32508081 0.         1.         0.         0.21470509 0.
 1.         0.32263731 0.         0.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.61412018 0.97646831 0.         1.         0.84038733 0.
 0.         0.         0.47927035 0.         0.         1.
 0.         0.58360093 0.43980574 0.         0.         0.
 1.         0.         0.         0.         1.         0.12620821]
wv_lg shape (30,)
[1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1.
 1. 0. 0. 0. 1. 0.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.75915786 0.6975947  0.74200665 0.68758587 0.68763164 0.24396449
 0.55874961 0.         0.         0.         0.93735806 1.
 0.         0.         0.         0.39621347 0.         1.
 0.33224043 1.         0.49514339 0.         0.         0.
 0.05551069 1.         1.         0.         0.48160955 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.         1.         1.         0.
 1.         0.97485504 1.         0.         0.         0.
 0.22819862 0.         1.         0.         0.         0.
 1.         0.         0.         0.         0.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         1.         0.36678871
  0.75915786 0.         0.        ]
 [0.         0.         0.         0.         1.         0.36678871
  0.6975947  0.         0.        ]
 [0.         0.         0.         0.         1.         0.36678871
  0.74200665 0.         0.        ]
 [0.         0.         0.         0.         1.         0.36678871
  0.68758587 0.         0.        ]
 [0.         0.         0.         0.         0.         0.36678871
  0.68763164 0.         0.        ]
 [0.         0.         1.         1.         0.         0.36678871
  0.24396449 1.         1.        ]
 [1.         0.         1.         0.61412018 0.         0.36678871
  0.55874961 0.         1.        ]
 [1.         0.         1.         0.97646831 0.         0.36678871
  0.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.36678871
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.36678871
  0.         1.         1.        ]
 [1.         0.         1.         0.84038733 0.         0.36678871
  0.93735806 1.         1.        ]
 [0.         0.15432371 0.         0.         1.         0.36678871
  1.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.36678871
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.         0.36678871
  0.         0.97485504 1.        ]
 [0.         0.         0.         0.47927035 0.         0.36678871
  0.         1.         1.        ]
 [0.         0.0203009  0.         0.         1.         0.36678871
  0.39621347 0.         1.        ]
 [0.         0.         0.59837597 0.         1.         0.36678871
  0.         0.         1.        ]
 [0.         0.         1.         1.         1.         0.36678871
  1.         0.         1.        ]
 [0.         0.         0.32508081 0.         0.         0.36678871
  0.33224043 0.22819862 1.        ]
 [0.         0.         0.         0.58360093 0.         0.36678871
  1.         0.         1.        ]
 [0.         0.         1.         0.43980574 0.         0.36678871
  0.49514339 1.         1.        ]
 [0.         1.         0.         0.         0.         0.36678871
  0.         0.         1.        ]
 [0.         0.2563228  0.21470509 0.         1.         0.36678871
  0.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.36678871
  0.         0.         1.        ]
 [0.0668861  0.         1.         1.         1.         0.36678871
  0.05551069 1.         1.        ]
 [0.         0.         0.32263731 0.         0.         0.36678871
  1.         0.         1.        ]
 [0.         0.732977   0.         0.         0.         0.36678871
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.         0.36678871
  0.         0.         1.        ]
 [1.         0.         1.         1.         1.         0.36678871
  0.48160955 0.         1.        ]
 [0.         0.         1.         0.12620821 0.         0.36678871
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.44366315 0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.01843188
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.31236169 0.         0.         0.
 0.         0.         0.         0.30615747 0.61785526 0.
 0.         1.         1.         1.         1.         0.
 0.68502569 1.         1.         0.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.40208767 0.         0.         0.54515514
 0.         0.         0.         1.         1.         0.23027951
 0.01014822 1.         1.         1.         1.         0.
 0.         1.         1.         0.         1.         0.30564668]
wv_lg shape (30,)
[0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.
 1. 0. 1. 0. 1. 1.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.65755866 0.         1.         0.
 0.         0.         0.         0.         0.05222588 0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.46264157]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.         0.         0.         0.63873059 1.
 1.         0.         0.         0.16944085 0.         1.
 0.78341516 0.         1.         1.         0.41932388 1.
 0.         0.90519148 0.         1.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.         0.34568892
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         0.         0.        ]
 [0.         0.01843188 0.         0.         1.         0.34568892
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.34568892
  0.         1.         1.        ]
 [0.         0.         0.         0.         1.         0.34568892
  1.         0.         1.        ]
 [0.         0.         0.31236169 0.40208767 1.         0.34568892
  0.65755866 0.         1.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         0.         1.        ]
 [1.         1.         0.         0.         0.         0.34568892
  1.         0.63873059 1.        ]
 [0.         0.         0.         0.54515514 0.         0.34568892
  0.         1.         1.        ]
 [0.44366315 0.         0.         0.         1.         0.34568892
  0.         1.         1.        ]
 [0.         0.         0.         0.         1.         0.34568892
  0.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.34568892
  0.         0.         1.        ]
 [0.         0.         0.30615747 1.         1.         0.34568892
  0.         0.16944085 1.        ]
 [0.         0.         0.61785526 1.         1.         0.34568892
  0.05222588 0.         1.        ]
 [0.         0.         0.         0.23027951 0.         0.34568892
  0.         1.         1.        ]
 [0.         1.         0.         0.01014822 1.         0.34568892
  1.         0.78341516 1.        ]
 [0.         0.         1.         1.         1.         0.34568892
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.34568892
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.34568892
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.34568892
  0.         0.41932388 1.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         1.         1.        ]
 [0.         0.         0.68502569 0.         1.         0.34568892
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.34568892
  0.         0.90519148 1.        ]
 [1.         0.         1.         1.         1.         0.34568892
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.         0.34568892
  0.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.34568892
  0.         0.         1.        ]
 [0.         0.         1.         0.30564668 1.         0.34568892
  0.46264157 0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.98909037
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         1.
 0.         0.         0.         1.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.68591513 1.         0.08303092 0.         0.
 0.         0.         0.         0.         0.         1.
 0.20713713 0.         0.         0.         0.45491869 0.
 1.         0.         0.         0.         0.20713713 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.90224519 0.         1.         0.12482284 0.95536724
 0.13362592 1.         1.         1.         1.         0.
 0.97223269 1.         1.         0.60444528 1.         0.
 1.         0.         1.         0.53516525 1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         0.56105379 0.75528835 0.44072878
 0.         1.         1.         0.073471   1.         0.
 0.91038708 1.         1.         0.90989858 1.         0.
 1.         0.         1.         1.         1.         0.14523145]
wv_lg shape (30,)
[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 0. 1.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.39627895 0.26406667 0.37047761 0.10709946 0.38725252 0.67801098
 0.         0.12555358 0.         0.39742936 1.         0.50809699
 1.         0.64787795 1.         0.         0.06058046 0.
 0.         0.         0.         0.         0.         0.
 0.         0.91929157 0.77632592 0.         0.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.61054943
 1.         1.         0.         1.         0.68111934 1.
 1.         0.97419887 1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         0.         1.         1.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.         0.44814751
  0.39627895 0.         0.        ]
 [0.         0.         0.         0.         0.         0.44814751
  0.26406667 0.         0.        ]
 [0.         0.         0.         0.         0.         0.44814751
  0.37047761 0.         0.        ]
 [0.         0.         0.         0.         0.         0.44814751
  0.10709946 0.         0.        ]
 [0.         0.         0.         0.         0.         0.44814751
  0.38725252 0.         0.        ]
 [0.         1.         1.         1.         0.         0.44814751
  0.67801098 0.61054943 1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  0.         1.         1.        ]
 [0.         0.68591513 0.90224519 1.         1.         0.44814751
  0.12555358 1.         1.        ]
 [0.         1.         0.         0.         0.         0.44814751
  0.         0.         1.        ]
 [0.         0.08303092 1.         0.56105379 0.         0.44814751
  0.39742936 1.         1.        ]
 [0.         0.         0.12482284 0.75528835 1.         0.44814751
  1.         0.68111934 1.        ]
 [0.98909037 0.         0.95536724 0.44072878 1.         0.44814751
  0.50809699 1.         1.        ]
 [0.         0.         0.13362592 0.         1.         0.44814751
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  0.64787795 0.97419887 1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  1.         1.         1.        ]
 [0.         0.         1.         0.073471   0.         0.44814751
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  0.06058046 1.         1.        ]
 [0.         1.         0.         0.         0.         0.44814751
  0.         1.         1.        ]
 [1.         0.20713713 0.97223269 0.91038708 0.         0.44814751
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  0.         1.         1.        ]
 [0.         0.         0.60444528 0.90989858 1.         0.44814751
  0.         1.         1.        ]
 [0.         0.45491869 1.         1.         0.         0.44814751
  0.         1.         1.        ]
 [1.         0.         0.         0.         0.         0.44814751
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.         0.44814751
  0.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.44814751
  0.91929157 0.         1.        ]
 [0.         0.         1.         1.         0.         0.44814751
  0.77632592 1.         1.        ]
 [1.         0.         0.53516525 1.         1.         0.44814751
  0.         1.         1.        ]
 [0.         0.20713713 1.         1.         0.         0.44814751
  0.         1.         1.        ]
 [0.         0.         1.         0.14523145 1.         0.44814751
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.79632248 0.         0.         0.21637872 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.45050642
 0.         1.         1.         1.         1.         0.
 1.         1.         1.         0.26117955 1.         1.
 0.44916509 0.25208698 1.         1.         1.         1.
 1.         1.         0.65546467 1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         1.         0.91868415
 1.         1.         1.         0.84207991 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         0.77267563 1.         1.         1.        ]
wv_lg shape (30,)
[1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.
 1. 1. 1. 1. 0. 1.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.3889442  0.37287008 0.41131868 0.20649123 0.30958496 0.63980934
 0.55298381 1.         0.70321471 1.         0.27473946 0.
 1.         0.35907079 0.8696068  0.         1.         0.
 0.         0.         1.         0.41628627 1.         0.09622108
 1.         0.21080269 0.4266899  0.25819036 1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.16249507 1.         1.         0.         0.46105429 0.
 1.         0.51621883 1.         0.78676848 1.         1.
 1.         0.24953428 0.89589653 1.         0.         1.
 1.         0.         1.         0.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         1.         0.50493056
  0.3889442  0.         0.        ]
 [0.         0.         0.         0.         0.         0.50493056
  0.37287008 0.         0.        ]
 [0.         0.         0.         0.         0.         0.50493056
  0.41131868 0.         0.        ]
 [0.         0.         0.         0.         0.         0.50493056
  0.20649123 0.         0.        ]
 [0.         0.         0.         0.         0.         0.50493056
  0.30958496 0.         0.        ]
 [1.         0.         0.45050642 1.         1.         0.50493056
  0.63980934 1.         1.        ]
 [0.         0.79632248 0.         0.         1.         0.50493056
  0.55298381 0.16249507 1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  1.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  0.70321471 1.         1.        ]
 [1.         0.21637872 1.         1.         0.         0.50493056
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.50493056
  0.27473946 0.46105429 1.        ]
 [0.         0.         0.         0.91868415 0.         0.50493056
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.50493056
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.50493056
  0.35907079 0.51621883 1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  0.8696068  1.         1.        ]
 [0.         0.         0.26117955 0.84207991 1.         0.50493056
  0.         0.78676848 1.        ]
 [0.         0.         1.         1.         0.         0.50493056
  1.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  0.         1.         1.        ]
 [0.         0.         0.44916509 1.         0.         0.50493056
  0.         1.         1.        ]
 [0.         0.         0.25208698 1.         0.         0.50493056
  0.         0.24953428 1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  1.         0.89589653 1.        ]
 [0.         0.         1.         1.         0.         0.50493056
  0.41628627 1.         1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  1.         0.         1.        ]
 [1.         0.         1.         1.         1.         0.50493056
  0.09622108 1.         1.        ]
 [0.         1.         1.         1.         1.         0.50493056
  1.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  0.21080269 0.         1.        ]
 [0.         0.         0.65546467 0.77267563 1.         0.50493056
  0.4266899  1.         1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  0.25819036 0.         1.        ]
 [0.         0.         1.         1.         0.         0.50493056
  1.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.50493056
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.98575066 0.         0.         0.         1.         1.
 0.         0.         0.         0.         1.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.71477908 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.37794674 0.         0.         0.
 0.         0.         0.10577457 1.         0.68036665 1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         0.08483517 0.         0.
 0.         0.37694048 0.         0.         1.         0.
 1.         0.         1.         1.         0.54856806 1.
 0.19251184 1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         0.22041014 0.62452127 0.
 1.         1.         0.         0.         1.         0.86830187
 1.         1.         1.         1.         1.         1.
 0.56487841 1.         1.         1.         1.         1.        ]
wv_lg shape (30,)
[1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.
 0. 0. 0. 1. 0. 0.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.60670523 0.24092454 0.40804352 0.25939116 0.15747206 0.41715442
 1.         1.         0.         0.         1.         0.07707511
 1.         1.         0.64070697 0.05803146 0.         0.47295119
 0.         0.62438101 0.62082186 1.         0.70047579 0.
 0.11545093 0.         0.         1.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.73402076
 0.         1.         0.53367925 0.         0.         0.
 0.         0.         0.         0.16027481 1.         0.
 1.         0.         0.         1.         1.         1.
 0.         0.         0.43251149 1.         0.56070326 0.65338621]
xy shape: (30, 9)
[[0.         0.         0.         0.         1.         0.41591561
  0.60670523 0.         0.        ]
 [0.         0.         0.         0.         0.         0.41591561
  0.24092454 0.         0.        ]
 [0.         0.         0.         0.         1.         0.41591561
  0.40804352 0.         0.        ]
 [0.         0.         0.         0.         0.         0.41591561
  0.25939116 0.         0.        ]
 [0.         0.         0.         0.         0.         0.41591561
  0.15747206 0.         0.        ]
 [1.         0.         1.         1.         1.         0.41591561
  0.41715442 0.73402076 1.        ]
 [0.         0.         1.         1.         0.         0.41591561
  1.         0.         1.        ]
 [0.         0.71477908 1.         1.         1.         0.41591561
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.         0.41591561
  0.         0.53367925 1.        ]
 [0.         0.         0.08483517 0.22041014 0.         0.41591561
  0.         0.         1.        ]
 [0.         0.         0.         0.62452127 0.         0.41591561
  1.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.41591561
  0.07707511 0.         1.        ]
 [0.         0.         0.         1.         0.         0.41591561
  1.         0.         1.        ]
 [0.         0.         0.37694048 1.         0.         0.41591561
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.         0.41591561
  0.64070697 0.         1.        ]
 [0.         0.         0.         0.         1.         0.41591561
  0.05803146 0.16027481 1.        ]
 [0.         0.         1.         1.         0.         0.41591561
  0.         1.         1.        ]
 [0.         0.         0.         0.86830187 0.         0.41591561
  0.47295119 0.         1.        ]
 [0.98575066 0.         1.         1.         1.         0.41591561
  0.         1.         1.        ]
 [0.         0.         0.         1.         0.         0.41591561
  0.62438101 0.         1.        ]
 [0.         0.37794674 1.         1.         0.         0.41591561
  0.62082186 0.         1.        ]
 [0.         0.         1.         1.         0.         0.41591561
  1.         1.         1.        ]
 [1.         0.         0.54856806 1.         1.         0.41591561
  0.70047579 1.         1.        ]
 [1.         0.         1.         1.         1.         0.41591561
  0.         1.         1.        ]
 [0.         0.         0.19251184 0.56487841 0.         0.41591561
  0.11545093 0.         1.        ]
 [0.         0.         1.         1.         0.         0.41591561
  0.         0.         1.        ]
 [0.         0.10577457 1.         1.         0.         0.41591561
  0.         0.43251149 1.        ]
 [0.         1.         1.         1.         1.         0.41591561
  1.         1.         1.        ]
 [1.         0.68036665 1.         1.         0.         0.41591561
  0.         0.56070326 1.        ]
 [0.         1.         1.         1.         0.         0.41591561
  0.         0.65338621 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.4757634  0.         0.         0.         1.         0.
 0.         0.         0.02179099 0.         0.         0.
 0.9514246  0.         0.         0.         0.57467884 0.
 0.         0.         0.         0.         0.34430777 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.87215695
 0.51673001 1.         1.         1.         0.         1.
 0.81979004 1.         1.         1.         1.         1.
 0.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         0.9302509 ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.70921882 1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         0.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_lg shape (30,)
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         1.         0.         1.         0.74867424
 0.53034069 0.         0.         0.38092228 0.         0.92009503
 0.         1.         1.         0.         0.45044324 0.
 0.         0.         0.66974423 0.         1.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.74873933 0.45062975 0.         0.2581053  0.
 0.         0.         0.         0.71059212 0.         0.43402686
 0.         0.67394701 0.88126703 0.         0.         1.
 0.32845458 0.         0.97739474 0.45761575 0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.         0.39932127
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.39932127
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.39932127
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.39932127
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.39932127
  0.         0.         0.        ]
 [0.         0.         0.87215695 1.         1.         0.39932127
  1.         0.         1.        ]
 [0.         0.4757634  0.51673001 0.70921882 0.         0.39932127
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.74873933 1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  1.         0.45062975 1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.         1.        ]
 [0.         1.         0.         0.         1.         0.39932127
  1.         0.2581053  1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.74867424 0.         1.        ]
 [0.         0.         0.81979004 1.         0.         0.39932127
  0.53034069 0.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.         1.        ]
 [0.         0.02179099 1.         1.         0.         0.39932127
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.38092228 0.71059212 1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.         1.        ]
 [1.         0.         1.         1.         1.         0.39932127
  0.92009503 0.43402686 1.        ]
 [0.         0.9514246  0.         0.         0.         0.39932127
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  1.         0.67394701 1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  1.         0.88126703 1.        ]
 [1.         0.         1.         1.         0.         0.39932127
  0.         0.         1.        ]
 [0.         0.57467884 0.         0.         1.         0.39932127
  0.45044324 0.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.32845458 1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.66974423 0.97739474 1.        ]
 [0.         0.         1.         1.         0.         0.39932127
  0.         0.45761575 1.        ]
 [1.         0.34430777 1.         1.         0.         0.39932127
  1.         0.         1.        ]
 [1.         0.         0.9302509  1.         0.         0.39932127
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.36721062 0.
 0.         0.         0.         0.         0.         0.
 0.         0.47786486 0.         0.         1.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.59583178 1.         1.         0.         1.
 0.34788097 1.         1.         1.         1.         1.
 1.         1.         1.         0.91243754 1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.         1.
 0.73395652 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_lg shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.61011968 0.78613539 0.69401528 0.61363137 0.88274639 0.
 1.         0.         1.         1.         0.36535418 1.
 1.         0.18992504 0.79711943 1.         0.79770992 1.
 0.53474502 0.         0.32995603 0.         0.         1.
 0.29011053 0.         1.         0.7092899  0.71356211 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.29546862
 0.         0.41926216 0.77425778 0.65264061 0.         0.868892
 0.10615673 1.         1.         1.         0.70850557 0.12005263
 0.94130332 1.         0.13884329 1.         0.37423586 1.
 1.         1.         0.95238793 0.73813286 1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.         0.48683226
  0.61011968 0.         0.        ]
 [0.         0.         0.         0.         0.         0.48683226
  0.78613539 0.         0.        ]
 [0.         0.         0.         0.         0.         0.48683226
  0.69401528 0.         0.        ]
 [0.         0.         0.         0.         0.         0.48683226
  0.61363137 0.         0.        ]
 [0.         0.         0.         0.         0.         0.48683226
  0.88274639 0.         0.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.         0.29546862 1.        ]
 [1.         0.         1.         1.         0.         0.48683226
  1.         0.         1.        ]
 [1.         0.         0.59583178 1.         0.         0.48683226
  0.         0.41926216 1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  1.         0.77425778 1.        ]
 [1.         0.         1.         1.         0.         0.48683226
  1.         0.65264061 1.        ]
 [0.         0.36721062 0.         0.         0.         0.48683226
  0.36535418 0.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  1.         0.868892   1.        ]
 [0.         0.         0.34788097 0.73395652 0.         0.48683226
  1.         0.10615673 1.        ]
 [0.         0.         1.         1.         1.         0.48683226
  0.18992504 1.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.79711943 1.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.79770992 0.70850557 1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  1.         0.12005263 1.        ]
 [1.         0.         1.         1.         0.         0.48683226
  0.53474502 0.94130332 1.        ]
 [0.         0.47786486 1.         1.         1.         0.48683226
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.         0.48683226
  0.32995603 0.13884329 1.        ]
 [1.         0.         0.91243754 1.         0.         0.48683226
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.         0.48683226
  0.         0.37423586 1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.29011053 1.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  1.         0.95238793 1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.7092899  0.73813286 1.        ]
 [0.         0.         1.         1.         0.         0.48683226
  0.71356211 1.         1.        ]
 [1.         0.         1.         1.         0.         0.48683226
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.         1.         1.         0.
 0.         0.74532112 1.         0.         1.         0.
 0.         0.         0.43187234 0.         0.33476924 0.
 0.88148867 0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.86871426
 1.         0.966274   1.         1.         0.         1.
 1.         1.         1.         1.         0.         1.
 1.         1.         0.09585813 0.62218714 1.         1.
 1.         1.         1.         0.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.26401514
 1.         0.02495496 1.         1.         0.         0.
 1.         1.         1.         1.         0.         1.
 1.         1.         0.29182194 0.         1.         1.
 1.         1.         1.         0.05034363 0.         1.        ]
wv_lg shape (30,)
[1.         1.         1.         1.         1.         0.33895142
 1.         1.         0.         0.         0.3530486  1.
 0.         0.         0.         1.         0.         0.1319737
 0.47539188 1.         0.05192302 0.52192787 0.         0.43309361
 1.         1.         0.79732569 0.         1.         0.77124066]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.11205109 0.
 0.30102084 0.16068871 0.26965268 0.         1.         0.
 0.52823624 1.         0.12613101 0.         0.         0.
 0.22687527 0.04598349 0.         0.         0.23464783 0.
 1.         0.22766807 0.50235274 0.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.20697119
 1.         0.49344452 0.00607823 1.         0.         1.
 0.         0.         0.27723784 1.         0.         1.
 1.         1.         0.         0.69477949 0.66963271 1.
 1.         1.         1.         0.         0.89968103 1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         1.         0.47681512
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.47681512
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.47681512
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.47681512
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.47681512
  0.11205109 0.         0.        ]
 [0.         0.         0.86871426 0.26401514 0.33895142 0.47681512
  0.         0.20697119 1.        ]
 [1.         1.         1.         1.         1.         0.47681512
  0.30102084 1.         1.        ]
 [0.         0.         0.966274   0.02495496 1.         0.47681512
  0.16068871 0.49344452 1.        ]
 [0.         0.         1.         1.         0.         0.47681512
  0.26965268 0.00607823 1.        ]
 [1.         1.         1.         1.         0.         0.47681512
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.3530486  0.47681512
  1.         0.         1.        ]
 [0.         0.         1.         0.         1.         0.47681512
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.47681512
  0.52823624 0.         1.        ]
 [0.         0.74532112 1.         1.         0.         0.47681512
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.         0.47681512
  0.12613101 0.27723784 1.        ]
 [1.         0.         1.         1.         1.         0.47681512
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.         0.47681512
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.1319737  0.47681512
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.47539188 0.47681512
  0.22687527 1.         1.        ]
 [0.         0.         1.         1.         1.         0.47681512
  0.04598349 1.         1.        ]
 [0.         0.43187234 0.09585813 0.29182194 0.05192302 0.47681512
  0.         0.         1.        ]
 [0.         0.         0.62218714 0.         0.52192787 0.47681512
  0.         0.69477949 1.        ]
 [1.         0.33476924 1.         1.         0.         0.47681512
  0.23464783 0.66963271 1.        ]
 [0.         0.         1.         1.         0.43309361 0.47681512
  0.         1.         1.        ]
 [1.         0.88148867 1.         1.         1.         0.47681512
  1.         1.         1.        ]
 [1.         0.         1.         1.         1.         0.47681512
  0.22766807 1.         1.        ]
 [0.         0.         1.         1.         0.79732569 0.47681512
  0.50235274 1.         1.        ]
 [0.         0.         0.         0.05034363 0.         0.47681512
  0.         0.         1.        ]
 [0.         0.         0.         0.         1.         0.47681512
  0.         0.89968103 1.        ]
 [1.         0.         1.         1.         0.77124066 0.47681512
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.        0.        0.        0.        0.        0.        0.
 1.        0.        0.        0.        0.1249524 0.        0.
 0.        0.        0.        0.        1.        0.        0.
 0.        1.        0.        0.        1.        0.        0.
 1.        0.       ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.54079547 0.         0.         0.
 0.         0.54079547 0.         0.78638724 0.         0.
 0.75979528 0.         0.         0.         0.01956042 0.49343018
 1.         0.01956042 0.66721588 0.         0.         0.37708518]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.99676684
 0.4766803  1.         0.24110436 0.         0.         1.
 0.77319187 1.         0.20900585 0.         1.         1.
 1.         1.         1.         1.         1.         1.
 0.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         0.         0.         0.         1.
 1.         0.         0.28420529 0.         1.         1.
 1.         1.         0.93998181 1.         1.         1.
 0.15975313 1.         0.94543005 1.         1.         1.        ]
wv_lg shape (30,)
[1.         1.         1.         1.         1.         0.
 0.75983331 0.44780599 0.43346466 0.64377975 1.         0.
 0.42495541 1.         0.         0.         0.3851193  1.
 0.         0.6853351  1.         1.         1.         0.
 0.         0.57556991 0.         1.         0.         0.        ]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.08424279 0.11427121 0.03613185 0.10767784 0.         1.
 0.         0.47024713 0.6849132  0.55252624 1.         0.
 0.01869656 0.         1.         0.         0.         0.
 0.18315753 0.41072597 0.         0.         0.         0.48135981
 1.         0.         0.         0.         0.11900422 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.17415876 1.         0.         0.         0.         0.58163649
 1.         1.         0.         0.         0.15775079 1.
 0.73818885 1.         1.         1.         1.         1.
 0.         1.         0.59731491 1.         1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         1.         0.46343152
  0.08424279 0.         0.        ]
 [0.         0.         0.         0.         1.         0.46343152
  0.11427121 0.         0.        ]
 [0.         0.         0.         0.         1.         0.46343152
  0.03613185 0.         0.        ]
 [0.         0.         0.         0.         1.         0.46343152
  0.10767784 0.         0.        ]
 [0.         0.         0.         0.         1.         0.46343152
  0.         0.         0.        ]
 [0.         1.         0.99676684 1.         0.         0.46343152
  1.         0.         1.        ]
 [0.         0.         0.4766803  0.         0.75983331 0.46343152
  0.         0.17415876 1.        ]
 [1.         0.         1.         1.         0.44780599 0.46343152
  0.47024713 1.         1.        ]
 [0.         0.54079547 0.24110436 0.         0.43346466 0.46343152
  0.6849132  0.         1.        ]
 [0.         0.         0.         0.         0.64377975 0.46343152
  0.55252624 0.         1.        ]
 [0.         0.         0.         0.         1.         0.46343152
  1.         0.         1.        ]
 [0.1249524  0.         1.         1.         0.         0.46343152
  0.         0.58163649 1.        ]
 [0.         0.         0.77319187 1.         0.42495541 0.46343152
  0.01869656 1.         1.        ]
 [0.         0.54079547 1.         0.         1.         0.46343152
  0.         1.         1.        ]
 [0.         0.         0.20900585 0.28420529 0.         0.46343152
  1.         0.         1.        ]
 [0.         0.78638724 0.         0.         0.         0.46343152
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.3851193  0.46343152
  0.         0.15775079 1.        ]
 [0.         0.         1.         1.         1.         0.46343152
  0.         1.         1.        ]
 [1.         0.75979528 1.         1.         0.         0.46343152
  0.18315753 0.73818885 1.        ]
 [0.         0.         1.         1.         0.6853351  0.46343152
  0.41072597 1.         1.        ]
 [0.         0.         1.         0.93998181 1.         0.46343152
  0.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.46343152
  0.         1.         1.        ]
 [1.         0.01956042 1.         1.         1.         0.46343152
  0.         1.         1.        ]
 [0.         0.49343018 1.         1.         0.         0.46343152
  0.48135981 1.         1.        ]
 [0.         1.         0.         0.15975313 0.         0.46343152
  1.         0.         1.        ]
 [1.         0.01956042 1.         1.         0.57556991 0.46343152
  0.         1.         1.        ]
 [0.         0.66721588 1.         0.94543005 0.         0.46343152
  0.         0.59731491 1.        ]
 [0.         0.         1.         1.         1.         0.46343152
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.         0.46343152
  0.11900422 1.         1.        ]
 [0.         0.37708518 1.         1.         0.         0.46343152
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         1.         0.         0.
 0.         0.         0.         0.         0.82636075 0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.2209708 ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.65215644
 1.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.44751832 1.         0.         0.         0.         1.
 0.         0.         0.         0.         0.         0.10508317]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.8288844
 0.         1.         0.95051653 1.         1.         1.
 0.         1.         1.         0.         1.         1.
 1.         0.         1.         1.         1.         0.
 0.88409744 0.85490488 1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.98252651
 0.         1.         0.24201789 1.         1.         1.
 0.         1.         1.         0.         1.         1.
 0.22163714 0.40092914 0.87648511 1.         1.         0.
 1.         0.8770351  1.         1.         1.         1.        ]
wv_lg shape (30,)
[1.         1.         1.         1.         1.         0.55533333
 0.         0.15011865 1.         0.         0.01763396 0.04244296
 1.         0.40428348 0.         1.         0.39018648 0.
 1.         0.         1.         0.         0.4494166  1.
 0.33816507 0.93405338 1.         0.85104573 0.84199284 1.        ]
wv_jc shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.86653158
 0.         1.         0.         0.         0.         0.
 1.         0.03143076 0.         1.         0.         0.
 0.         0.77226037 0.         0.         1.         0.
 1.         0.         0.         0.         0.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.91502913 0.74427481 0.84325501 1.         0.23637429
 0.         1.         0.22973243 0.50301112 1.         0.57017934
 1.         0.         1.         0.22448796 0.36871477 1.
 0.51081526 1.         1.         1.         1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         1.         0.46734122
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.46734122
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.46734122
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.46734122
  0.         0.         0.        ]
 [0.         0.         0.         0.         1.         0.46734122
  0.         0.         0.        ]
 [0.         0.65215644 0.8288844  0.98252651 0.55533333 0.46734122
  0.86653158 0.         1.        ]
 [0.         1.         0.         0.         0.         0.46734122
  0.         0.         1.        ]
 [1.         1.         1.         1.         0.15011865 0.46734122
  1.         0.91502913 1.        ]
 [0.         0.         0.95051653 0.24201789 1.         0.46734122
  0.         0.74427481 1.        ]
 [1.         0.         1.         1.         0.         0.46734122
  0.         0.84325501 1.        ]
 [0.         0.         1.         1.         0.01763396 0.46734122
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.04244296 0.46734122
  0.         0.23637429 1.        ]
 [0.         0.         0.         0.         1.         0.46734122
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.40428348 0.46734122
  0.03143076 1.         1.        ]
 [0.         0.         1.         1.         0.         0.46734122
  0.         0.22973243 1.        ]
 [0.         0.         0.         0.         1.         0.46734122
  1.         0.50301112 1.        ]
 [0.82636075 0.         1.         1.         0.39018648 0.46734122
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.46734122
  0.         0.57017934 1.        ]
 [0.         0.44751832 1.         0.22163714 1.         0.46734122
  0.         1.         1.        ]
 [0.         1.         0.         0.40092914 0.         0.46734122
  0.77226037 0.         1.        ]
 [0.         0.         1.         0.87648511 1.         0.46734122
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.46734122
  0.         0.22448796 1.        ]
 [0.         0.         1.         1.         0.4494166  0.46734122
  1.         0.36871477 1.        ]
 [0.         1.         0.         0.         1.         0.46734122
  0.         1.         1.        ]
 [0.         0.         0.88409744 1.         0.33816507 0.46734122
  1.         0.51081526 1.        ]
 [0.         0.         0.85490488 0.8770351  0.93405338 0.46734122
  0.         1.         1.        ]
 [0.         0.         1.         1.         1.         0.46734122
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.85104573 0.46734122
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.84199284 0.46734122
  0.         1.         1.        ]
 [0.2209708  0.10508317 1.         1.         1.         0.46734122
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.42463109 0.
 1.         1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.23584777 1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.99774779 1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.63825714 1.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.07618076 1.         1.        ]
wv_lg shape (30,)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_jc shape (30, 7)
[[0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.
 0.34689683 0.         0.         0.42992796 0.4300551  0.
 0.         0.         0.54078023 1.         0.         0.
 0.         0.         0.60485571 0.         1.         0.39089878
 0.         0.         0.94908643 0.         0.00628676 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.65632189 0.8222566  0.         1.         0.04003278 1.
 1.         0.         0.91975398 1.         1.         1.
 1.         1.         1.         0.         1.         1.
 1.         0.78718113 1.         0.11422537 0.83668041 0.        ]
xy shape: (30, 15)
[[0.         0.         0.         0.         1.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         0.         0.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.34689683 0.65632189 1.        ]
 [1.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.8222566  1.        ]
 [1.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.42992796 1.         1.        ]
 [0.         0.42463109 0.23584777 0.63825714 0.         0.
  0.         0.         0.         0.         0.         0.
  0.4300551  0.04003278 1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.54078023 0.91975398 1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.60485571 1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.39089878 1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.78718113 1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.94908643 1.         1.        ]
 [0.         1.         0.99774779 0.07618076 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.11422537 1.        ]
 [1.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.00628676 0.83668041 1.        ]
 [0.         0.         1.         1.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         1.        ]]
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.42307331 0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         1.         0.
 0.         0.         0.         0.         1.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.3377287  1.         0.40175208
 0.         0.         0.40175208 0.         0.72828917 0.
 0.63975971 1.         1.         0.         0.         0.
 0.91812183 0.         0.         0.         0.         0.8732729 ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.29566899
 0.         0.78692963 0.96355918 0.63988285 1.         0.01736812
 0.         0.44052885 0.         0.78937466 1.         0.62258102
 0.774353   0.         1.         0.58531931 1.         0.72842825
 0.         0.         1.         0.57098601 1.         0.8002716 ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.63750754
 0.43684131 1.         1.         1.         1.         0.58887308
 0.08622767 0.82137711 0.         1.         1.         0.87146762
 1.         0.         1.         0.75658697 1.         1.
 0.49956282 0.66465063 1.         1.         1.         1.        ]
wv_lg shape (30, 7)
[[1.75759960e-02 5.30098200e-01            nan            nan
  3.01366478e-01 4.70235478e-03            nan]
 [1.74226165e-02 5.30377388e-01            nan            nan
  3.01432133e-01 4.74342098e-03            nan]
 [1.74940974e-02 5.30633092e-01            nan            nan
  3.01384687e-01 4.75809956e-03            nan]
 [1.75034534e-02 5.30555844e-01            nan            nan
  3.01337034e-01 4.73161647e-03            nan]
 [1.74996909e-02 5.30414760e-01            nan            nan
  3.01293850e-01 4.72459989e-03            nan]
 [1.78701654e-02 5.21228492e-01            nan            nan
  3.12652647e-01            nan            nan]
 [1.64507292e-02 5.20463049e-01            nan            nan
  3.12039882e-01 5.58401574e-04            nan]
 [1.76682714e-02 5.20455420e-01            nan            nan
  3.11443508e-01            nan            nan]
 [1.63488034e-02 5.20954132e-01            nan            nan
  3.12546164e-01            nan            nan]
 [1.61433332e-02 5.20234764e-01            nan            nan
  3.10179591e-01            nan            nan]
 [1.46717522e-02 5.22442698e-01            nan            nan
  3.09440732e-01 1.64707541e-04            nan]
 [1.71978846e-02 5.21870136e-01            nan            nan
  3.10119510e-01 1.12177288e-04            nan]
 [1.65704433e-02 5.20560324e-01            nan            nan
  3.12467784e-01 5.36649371e-04            nan]
 [1.69656873e-02 5.21032989e-01            nan            nan
  3.10578793e-01            nan            nan]
 [1.58383008e-02 5.20946026e-01            nan            nan
  3.11361045e-01 2.57324835e-04            nan]
 [1.62120853e-02 5.21228850e-01            nan            nan
  3.11815679e-01 9.88512649e-04            nan]
 [1.73788052e-02 5.20748556e-01            nan            nan
  3.09838951e-01            nan            nan]
 [1.73910875e-02 5.20736933e-01            nan            nan
  3.11586261e-01 4.72946733e-04            nan]
 [1.60768926e-02 5.22080243e-01            nan            nan
  3.12064588e-01            nan            nan]
 [1.70731135e-02 5.19850850e-01            nan            nan
  3.12157601e-01 7.42429169e-04            nan]
 [1.53344693e-02 5.22658348e-01            nan            nan
  3.09806734e-01 1.50023858e-04            nan]
 [1.73618346e-02 5.21212280e-01            nan            nan
  3.11573744e-01 4.01761965e-04            nan]
 [1.64807346e-02 5.21957219e-01            nan            nan
  3.08183968e-01 8.43097863e-04            nan]
 [1.65467747e-02 5.20741999e-01            nan            nan
  3.12931180e-01            nan            nan]
 [1.64704230e-02 5.20148098e-01            nan            nan
  3.14532965e-01 7.90440026e-05            nan]
 [1.65828895e-02 5.20996332e-01            nan            nan
  3.12698275e-01            nan            nan]
 [1.69421453e-02 5.23046374e-01            nan            nan
  3.12829256e-01            nan            nan]
 [1.64585263e-02 5.22056937e-01            nan            nan
  3.12631249e-01 4.90889943e-04            nan]
 [1.53781604e-02 5.21672785e-01            nan            nan
  3.06983441e-01 9.48298490e-04            nan]
 [1.62228961e-02 5.21855354e-01            nan            nan
  3.12885255e-01 1.50148422e-04            nan]]
wv_jc shape (30, 7)
[[0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         0.         1.
 0.88630691 1.         0.77194341 0.76122872 1.         1.
 1.         1.         0.         1.         0.67507276 1.
 1.         1.         1.         0.53951156 0.40549492 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.10111786 0.         0.68681757 0.
 1.         1.         0.         1.         1.         1.
 0.         0.15331101 0.         0.         1.         1.
 0.26663807 1.         0.         0.80999699 0.         0.        ]
xy shape: (30, 21)
[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.75759960e-02 5.30098200e-01 2.40880464e-01 2.40880464e-01
  3.01366478e-01 4.70235478e-03 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.74226165e-02 5.30377388e-01 2.40880464e-01 2.40880464e-01
  3.01432133e-01 4.74342098e-03 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.74940974e-02 5.30633092e-01 2.40880464e-01 2.40880464e-01
  3.01384687e-01 4.75809956e-03 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.75034534e-02 5.30555844e-01 2.40880464e-01 2.40880464e-01
  3.01337034e-01 4.73161647e-03 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.74996909e-02 5.30414760e-01 2.40880464e-01 2.40880464e-01
  3.01293850e-01 4.72459989e-03 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00]
 [0.00000000e+00 0.00000000e+00 2.95668986e-01 6.37507540e-01
  1.78701654e-02 5.21228492e-01 2.40880464e-01 2.40880464e-01
  3.12652647e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.36841311e-01
  1.64507292e-02 5.20463049e-01 2.40880464e-01 2.40880464e-01
  3.12039882e-01 5.58401574e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 7.86929632e-01 1.00000000e+00
  1.76682714e-02 5.20455420e-01 2.40880464e-01 2.40880464e-01
  3.11443508e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 9.63559180e-01 1.00000000e+00
  1.63488034e-02 5.20954132e-01 2.40880464e-01 2.40880464e-01
  3.12546164e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.01117858e-01
  1.00000000e+00]
 [4.23073315e-01 3.37728697e-01 6.39882848e-01 1.00000000e+00
  1.61433332e-02 5.20234764e-01 2.40880464e-01 2.40880464e-01
  3.10179591e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  1.46717522e-02 5.22442698e-01 2.40880464e-01 2.40880464e-01
  3.09440732e-01 1.64707541e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.86817570e-01
  1.00000000e+00]
 [0.00000000e+00 4.01752078e-01 1.73681249e-02 5.88873078e-01
  1.71978846e-02 5.21870136e-01 2.40880464e-01 2.40880464e-01
  3.10119510e-01 1.12177288e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 8.62276682e-02
  1.65704433e-02 5.20560324e-01 2.40880464e-01 2.40880464e-01
  3.12467784e-01 5.36649371e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 8.86306908e-01 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 4.40528854e-01 8.21377112e-01
  1.69656873e-02 5.21032989e-01 2.40880464e-01 2.40880464e-01
  3.10578793e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 4.01752078e-01 0.00000000e+00 0.00000000e+00
  1.58383008e-02 5.20946026e-01 2.40880464e-01 2.40880464e-01
  3.11361045e-01 2.57324835e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 7.71943406e-01 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 7.89374660e-01 1.00000000e+00
  1.62120853e-02 5.21228850e-01 2.40880464e-01 2.40880464e-01
  3.11815679e-01 9.88512649e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 7.61228720e-01 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 7.28289175e-01 1.00000000e+00 1.00000000e+00
  1.73788052e-02 5.20748556e-01 2.40880464e-01 2.40880464e-01
  3.09838951e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 6.22581017e-01 8.71467622e-01
  1.73910875e-02 5.20736933e-01 2.40880464e-01 2.40880464e-01
  3.11586261e-01 4.72946733e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 6.39759714e-01 7.74352995e-01 1.00000000e+00
  1.60768926e-02 5.22080243e-01 2.40880464e-01 2.40880464e-01
  3.12064588e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00
  1.70731135e-02 5.19850850e-01 2.40880464e-01 2.40880464e-01
  3.12157601e-01 7.42429169e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.53311011e-01
  1.00000000e+00]
 [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00
  1.53344693e-02 5.22658348e-01 2.40880464e-01 2.40880464e-01
  3.09806734e-01 1.50023858e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 5.85319310e-01 7.56586970e-01
  1.73618346e-02 5.21212280e-01 2.40880464e-01 2.40880464e-01
  3.11573744e-01 4.01761965e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.64807346e-02 5.21957219e-01 2.40880464e-01 2.40880464e-01
  3.08183968e-01 8.43097863e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 6.75072755e-01 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 7.28428255e-01 1.00000000e+00
  1.65467747e-02 5.20741999e-01 2.40880464e-01 2.40880464e-01
  3.12931180e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 9.18121834e-01 0.00000000e+00 4.99562815e-01
  1.64704230e-02 5.20148098e-01 2.40880464e-01 2.40880464e-01
  3.14532965e-01 7.90440026e-05 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 2.66638072e-01
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.64650627e-01
  1.65828895e-02 5.20996332e-01 2.40880464e-01 2.40880464e-01
  3.12698275e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.69421453e-02 5.23046374e-01 2.40880464e-01 2.40880464e-01
  3.12829256e-01 2.40880464e-01 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00
  1.00000000e+00]
 [0.00000000e+00 0.00000000e+00 5.70986013e-01 1.00000000e+00
  1.64585263e-02 5.22056937e-01 2.40880464e-01 2.40880464e-01
  3.12631249e-01 4.90889943e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 5.39511565e-01 8.09996988e-01
  1.00000000e+00]
 [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00
  1.53781604e-02 5.21672785e-01 2.40880464e-01 2.40880464e-01
  3.06983441e-01 9.48298490e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 4.05494922e-01 0.00000000e+00
  1.00000000e+00]
 [1.00000000e+00 8.73272896e-01 8.00271604e-01 1.00000000e+00
  1.62228961e-02 5.21855354e-01 2.40880464e-01 2.40880464e-01
  3.12885255e-01 1.50148422e-04 2.40880464e-01 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
  1.00000000e+00]]
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 1. 0. 0. 1. 0. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.70165887 0.22306825 0.81382014 0.         0.13897265 0.60577933
 0.88729904 0.60577933 0.         1.         1.         0.
 0.43051593 0.         0.         0.         0.         1.
 0.         0.         1.         0.         0.98469682 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.7842484
 0.39555411 1.         1.         0.60534535 1.         0.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         0.83261635 0.
 1.         1.         0.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.3314067  1.         1.         1.         1.         0.
 1.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         0.89200207 0.04110636
 1.         1.         0.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.2395671 ]
 [0.23956917]
 [0.23960527]
 [0.23958549]
 [0.23959201]
 [0.2368231 ]
 [0.23750785]
 [0.23704654]
 [0.23798559]
 [0.2372257 ]
 [0.23739415]
 [0.23708813]
 [0.23745651]
 [0.2373425 ]
 [0.237309  ]
 [0.23794741]
 [0.23694455]
 [0.23734456]
 [0.23760408]
 [0.23753477]
 [0.23736923]
 [0.23803988]
 [0.23823718]
 [0.23740696]
 [0.23766966]
 [0.23817572]
 [0.23736047]
 [0.23793737]
 [0.23770357]
 [0.23796029]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.28594859 0.8219609  1.         1.         0.         0.89637296
 0.         0.         1.         1.         1.         1.
 1.         1.         1.         1.         0.         0.97642298
 1.         1.         0.81218675 1.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.2395671  1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.23956917 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.23960527 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.23958549 1.
  1.         0.         0.        ]
 [0.         0.         0.         0.         0.23959201 1.
  1.         0.         0.        ]
 [1.         0.         0.7842484  1.         0.2368231  1.
  0.         1.         1.        ]
 [0.         0.70165887 0.39555411 0.3314067  0.23750785 1.
  0.         0.28594859 1.        ]
 [0.         0.22306825 1.         1.         0.23704654 1.
  0.         0.8219609  1.        ]
 [0.         0.81382014 1.         1.         0.23798559 1.
  0.         1.         1.        ]
 [1.         0.         0.60534535 1.         0.2372257  1.
  0.         1.         1.        ]
 [1.         0.13897265 1.         1.         0.23739415 1.
  0.         0.         1.        ]
 [0.         0.60577933 0.         0.         0.23708813 1.
  0.         0.89637296 1.        ]
 [0.         0.88729904 1.         1.         0.23745651 1.
  0.         0.         1.        ]
 [0.         0.60577933 0.         0.         0.2373425  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.237309   1.
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.23794741 1.
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.23694455 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23734456 1.
  0.         1.         1.        ]
 [0.         0.43051593 1.         1.         0.23760408 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23753477 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.23736923 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23803988 1.
  0.         1.         1.        ]
 [0.         0.         0.83261635 0.89200207 0.23823718 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.04110636 0.23740696 1.
  0.         0.97642298 1.        ]
 [1.         0.         1.         1.         0.23766966 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23817572 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.23736047 1.
  0.         0.81218675 1.        ]
 [1.         0.         1.         1.         0.23793737 1.
  0.         1.         1.        ]
 [0.         0.98469682 1.         1.         0.23770357 1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.23796029 1.
  0.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         1.         0.
 0.         0.42476072 0.86489687 1.         0.         0.
 0.         0.01411415 0.13236886 0.         0.         0.01411415
 0.         1.         1.         0.         0.         0.72760376]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         0.         1.
 0.59352867 0.2462777  1.         0.         1.         0.62532879
 1.         0.41013546 1.         1.         1.         1.
 1.         0.97864188 1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         0.38210879 1.
 1.         0.5772227  1.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.61473336 0.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.23781573]
 [0.23784405]
 [0.2377707 ]
 [0.23793198]
 [0.23783915]
 [0.23685404]
 [0.23650697]
 [0.23662345]
 [0.23690283]
 [0.23724328]
 [0.23687332]
 [0.23722621]
 [0.23760204]
 [0.23699091]
 [0.23692163]
 [0.23732609]
 [0.23736671]
 [0.23723258]
 [0.23749072]
 [0.23661425]
 [0.23778274]
 [0.23785653]
 [0.23763019]
 [0.23749125]
 [0.2365413 ]
 [0.23782441]
 [0.2370061 ]
 [0.23717643]
 [0.23719163]
 [0.23703583]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.24534983 0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.54781844 1.         1.         0.94539086 0.74930471 1.
 0.         1.         0.29034945 0.11662885 1.         0.91206934
 1.         1.         0.669918   1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23781573 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23784405 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.2377707  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23793198 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23783915 1.
  0.         0.         0.        ]
 [0.         0.         1.         1.         0.23685404 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.23650697 1.
  0.         0.54781844 1.        ]
 [0.         0.         1.         1.         0.23662345 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23690283 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23724328 1.
  0.         0.94539086 1.        ]
 [0.         1.         0.         0.38210879 0.23687332 1.
  0.         0.74930471 1.        ]
 [1.         0.         1.         1.         0.23722621 1.
  0.         1.         1.        ]
 [0.         0.         0.59352867 1.         0.23760204 1.
  0.         0.         1.        ]
 [0.         0.42476072 0.2462777  0.5772227  0.23699091 1.
  0.         1.         1.        ]
 [0.         0.86489687 1.         1.         0.23692163 1.
  1.         0.29034945 1.        ]
 [0.         1.         0.         0.         0.23732609 1.
  0.         0.11662885 1.        ]
 [0.         0.         1.         1.         0.23736671 1.
  0.         1.         1.        ]
 [0.         0.         0.62532879 1.         0.23723258 1.
  0.         0.91206934 1.        ]
 [0.         0.         1.         1.         0.23749072 1.
  0.24534983 1.         1.        ]
 [0.         0.01411415 0.41013546 1.         0.23661425 1.
  0.         1.         1.        ]
 [0.         0.13236886 1.         1.         0.23778274 1.
  1.         0.669918   1.        ]
 [1.         0.         1.         1.         0.23785653 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23763019 1.
  0.         1.         1.        ]
 [0.         0.01411415 1.         1.         0.23749125 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.2365413  1.
  0.         1.         1.        ]
 [0.         1.         0.97864188 0.61473336 0.23782441 1.
  0.         1.         1.        ]
 [1.         1.         1.         0.         0.2370061  1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23717643 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23719163 1.
  0.         1.         1.        ]
 [0.         0.72760376 1.         1.         0.23703583 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 1 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.50486358 0.         1.
 0.         0.         1.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         0.38818137 0.         0.         1.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.09023843 0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.         1.         0.         1.         0.
 0.         0.         1.         0.4547845  0.64071447 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.58946235 1.         1.         1.         1.         1.
 0.         1.         0.         1.         1.         1.
 0.         0.88523272 0.         1.         0.         1.
 1.         1.         0.         0.50377569 1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.67868742 1.         0.35078459 1.         0.
 0.         1.         0.         0.54892908 1.         0.26770504
 1.         1.         0.         1.         0.         1.
 0.20830424 0.47156038 1.         1.         1.         0.45801856]
wv_lg shape (30, 1)
[[0.2371887 ]
 [0.23705994]
 [0.23711691]
 [0.23694115]
 [0.23726424]
 [0.23750812]
 [0.23602221]
 [0.23652147]
 [0.2355587 ]
 [0.23630091]
 [0.23630225]
 [0.23630079]
 [0.23722526]
 [0.23554711]
 [0.23765438]
 [0.23570058]
 [0.23570468]
 [0.23729869]
 [0.23702785]
 [0.23767873]
 [0.23611712]
 [0.23742375]
 [0.23503405]
 [0.23497205]
 [0.23551824]
 [0.23711385]
 [0.23633264]
 [0.2369764 ]
 [0.23732393]
 [0.23636928]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.28625412 0.90859034 0.49371632 0.57076141
 0.         0.58965203 0.94108418 0.768064   0.32308694 1.
 0.         0.47485388 0.9339579  0.         1.         0.85620483
 0.         1.         0.         0.41617573 1.         0.44253181]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.         1.         0.         1.
 1.         1.         0.20085244 1.         1.         0.99542057
 0.         1.         1.         1.         1.         0.
 1.         1.         0.3726999  1.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.2371887  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23705994 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23711691 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23694115 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23726424 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23750812 1.
  0.         0.         1.        ]
 [0.         0.09023843 0.58946235 0.         0.23602221 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.67868742 0.23652147 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.2355587  1.
  0.28625412 0.         1.        ]
 [0.50486358 0.         1.         0.35078459 0.23630091 1.
  0.90859034 1.         1.        ]
 [0.         0.         1.         1.         0.23630225 1.
  0.49371632 0.         1.        ]
 [1.         0.         1.         0.         0.23630079 1.
  0.57076141 1.         1.        ]
 [0.         0.         0.         0.         0.23722526 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23554711 1.
  0.58965203 1.         1.        ]
 [1.         1.         0.         0.         0.23765438 1.
  0.94108418 0.20085244 1.        ]
 [0.         0.         1.         0.54892908 0.23570058 1.
  0.768064   1.         1.        ]
 [0.         0.         1.         1.         0.23570468 1.
  0.32308694 1.         1.        ]
 [0.         0.         1.         0.26770504 0.23729869 1.
  1.         0.99542057 1.        ]
 [0.         0.         0.         1.         0.23702785 1.
  0.         0.         1.        ]
 [0.         0.         0.88523272 1.         0.23767873 1.
  0.47485388 1.         1.        ]
 [1.         1.         0.         0.         0.23611712 1.
  0.9339579  1.         1.        ]
 [0.         0.         1.         1.         0.23742375 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.23503405 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23497205 1.
  0.85620483 0.         1.        ]
 [0.         0.         1.         0.20830424 0.23551824 1.
  0.         1.         1.        ]
 [0.         0.         1.         0.47156038 0.23711385 1.
  1.         1.         1.        ]
 [0.38818137 1.         0.         1.         0.23633264 1.
  0.         0.3726999  1.        ]
 [0.         0.4547845  0.50377569 1.         0.2369764  1.
  0.41617573 1.         1.        ]
 [0.         0.64071447 1.         1.         0.23732393 1.
  1.         1.         1.        ]
 [1.         0.         1.         0.45801856 0.23636928 1.
  0.44253181 0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 2 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         1.         0.         1.         0.         0.
 0.         0.39625359 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.46768969 1.         1.         0.         1.         1.
 0.73156465 0.99303992 1.         0.77314568 1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         1.         0.         1.         1.
 0.         0.         1.         0.         1.         1.
 1.         0.11368744 0.         0.         0.7033402  1.
 1.         1.         1.         1.         1.         0.1754489 ]
wv_lg shape (30, 1)
[[0.23695193]
 [0.23699883]
 [0.23703251]
 [0.23704298]
 [0.23708913]
 [0.23685887]
 [0.23682684]
 [0.23767443]
 [0.23722711]
 [0.23635018]
 [0.23711189]
 [0.23617351]
 [0.23733568]
 [0.23767306]
 [0.23734401]
 [0.23703395]
 [0.23710828]
 [0.23694715]
 [0.23615986]
 [0.2365221 ]
 [0.23650811]
 [0.23712144]
 [0.23656876]
 [0.23669628]
 [0.23695833]
 [0.23717009]
 [0.2370639 ]
 [0.23628246]
 [0.23627992]
 [0.23759822]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.99955659 0.23555947 0.97710729 0.30769165
 0.74307294 0.41569169 0.         1.         0.6200784  1.
 0.         0.98331713 1.         0.78779783 0.97090075 0.5682888
 0.         1.         1.         0.31032619 0.20535605 0.01606762]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.42686421 1.         1.         0.         1.         1.
 0.72880281 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         0.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23695193 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23699883 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23703251 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23704298 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23708913 1.
  0.         0.         0.        ]
 [1.         0.         1.         0.         0.23685887 1.
  1.         1.         1.        ]
 [0.         0.         0.46768969 0.         0.23682684 1.
  0.         0.42686421 1.        ]
 [0.         0.         1.         1.         0.23767443 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23722711 1.
  0.99955659 1.         1.        ]
 [0.         0.         0.         0.         0.23635018 1.
  0.23555947 0.         1.        ]
 [0.         0.         1.         1.         0.23711189 1.
  0.97710729 1.         1.        ]
 [0.         0.         1.         1.         0.23617351 1.
  0.30769165 1.         1.        ]
 [1.         0.         0.73156465 0.         0.23733568 1.
  0.74307294 0.72880281 1.        ]
 [0.         1.         0.99303992 0.         0.23767306 1.
  0.41569169 1.         1.        ]
 [0.         0.         1.         1.         0.23734401 1.
  0.         1.         1.        ]
 [0.         1.         0.77314568 0.         0.23703395 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23710828 1.
  0.6200784  1.         1.        ]
 [0.         0.         1.         1.         0.23694715 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23615986 1.
  0.         1.         1.        ]
 [1.         0.39625359 1.         0.11368744 0.2365221  1.
  0.98331713 1.         1.        ]
 [1.         0.         1.         0.         0.23650811 1.
  1.         1.         1.        ]
 [0.         0.         1.         0.         0.23712144 1.
  0.78779783 1.         1.        ]
 [0.         0.         1.         0.7033402  0.23656876 1.
  0.97090075 1.         1.        ]
 [0.         0.         1.         1.         0.23669628 1.
  0.5682888  1.         1.        ]
 [0.         0.         1.         1.         0.23695833 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23717009 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.2370639  1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23628246 1.
  0.31032619 0.         1.        ]
 [0.         0.         1.         1.         0.23627992 1.
  0.20535605 0.         1.        ]
 [1.         0.         1.         0.1754489  0.23759822 1.
  0.01606762 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 3 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 1. 0. 0. 1. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.13729565 0.04242748 1.         0.         0.
 0.         0.         0.         1.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         1.         0.44898759
 0.         1.         1.         0.72089058 0.3831861  0.
 0.94331771 0.         1.         0.         0.94090005 0.
 1.         0.13903564 1.         0.         1.         0.49612153]
wv_ed shape (30,)
[0.         0.         0.13418975 0.         0.26130983 0.57472
 1.         1.         0.         0.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.         1.         1.
 1.         1.         0.59026909 0.87403252 1.         1.        ]
wv_lg shape (30, 1)
[[0.2369561 ]
 [0.23703558]
 [0.2370363 ]
 [0.23677435]
 [0.23693842]
 [0.23702664]
 [0.23614297]
 [0.23730051]
 [0.23756682]
 [0.23728533]
 [0.23732641]
 [0.23702147]
 [0.23656942]
 [0.23746178]
 [0.23717058]
 [0.23724907]
 [0.23716359]
 [0.23615632]
 [0.23714493]
 [0.2376625 ]
 [0.23709908]
 [0.23627871]
 [0.23717923]
 [0.23705347]
 [0.23649117]
 [0.23763927]
 [0.23686766]
 [0.23752613]
 [0.23682509]
 [0.23714074]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.89376888 0.59409946 1.         0.34651364 1.         0.36091286
 0.49099626 1.         0.16309377 1.         1.         1.
 1.         1.         1.         1.         1.         0.40236077
 1.         1.         1.         1.         1.         0.55240859]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.88005194 1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         0.19907806 0.19896924
 1.         0.         1.         0.92277877 1.         0.77975601]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.2369561  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23703558 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.13418975 0.2370363  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23677435 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.26130983 0.23693842 1.
  0.         0.         0.        ]
 [0.         0.         1.         0.57472    0.23702664 1.
  1.         0.         1.        ]
 [0.         0.         0.         1.         0.23614297 1.
  0.89376888 1.         1.        ]
 [0.         0.         0.         1.         0.23730051 1.
  0.59409946 0.         1.        ]
 [0.         0.         0.         0.         0.23756682 1.
  1.         0.88005194 1.        ]
 [0.         1.         0.         0.         0.23728533 1.
  0.34651364 1.         1.        ]
 [0.         0.         1.         1.         0.23732641 1.
  1.         1.         1.        ]
 [0.         0.         0.44898759 1.         0.23702147 1.
  0.36091286 1.         1.        ]
 [0.         0.         0.         1.         0.23656942 1.
  0.49099626 1.         1.        ]
 [0.         0.         1.         1.         0.23746178 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23717058 1.
  0.16309377 1.         1.        ]
 [0.         0.         0.72089058 1.         0.23724907 1.
  1.         1.         1.        ]
 [0.         0.         0.3831861  1.         0.23716359 1.
  1.         1.         1.        ]
 [0.         0.         0.         1.         0.23615632 1.
  1.         1.         1.        ]
 [0.         0.         0.94331771 1.         0.23714493 1.
  1.         1.         1.        ]
 [0.         0.13729565 0.         1.         0.2376625  1.
  1.         1.         1.        ]
 [0.         0.04242748 1.         1.         0.23709908 1.
  1.         1.         1.        ]
 [1.         1.         0.         0.         0.23627871 1.
  1.         1.         1.        ]
 [0.         0.         0.94090005 1.         0.23717923 1.
  1.         0.19907806 1.        ]
 [0.         0.         0.         1.         0.23705347 1.
  0.40236077 0.19896924 1.        ]
 [1.         0.         1.         1.         0.23649117 1.
  1.         1.         1.        ]
 [0.         0.         0.13903564 1.         0.23763927 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.59026909 0.23686766 1.
  1.         1.         1.        ]
 [1.         1.         0.         0.87403252 0.23752613 1.
  1.         0.92277877 1.        ]
 [0.         0.         1.         1.         0.23682509 1.
  1.         1.         1.        ]
 [0.         0.         0.49612153 1.         0.23714074 1.
  0.55240859 0.77975601 1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 4 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.03386935 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.58566403 0.         0.42377644 0.         0.
 0.         0.         1.         0.         1.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.09532774 1.         0.
 0.         0.53602198 0.         0.         0.         0.10242988
 0.         0.         1.         0.         0.         0.
 0.         0.         0.         0.         0.65254351 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.         0.         0.         1.
 1.         1.         1.         1.         0.24650762 0.
 1.         1.         0.64373371 0.43848735 0.         1.
 1.         1.         1.         0.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.01258005 0.         0.         1.
 0.42978684 1.         1.         0.91856258 0.42676087 0.
 1.         1.         0.87196145 1.         0.         1.
 1.         1.         1.         0.22589494 0.99686289 1.        ]
wv_lg shape (30, 1)
[[0.23632401]
 [0.23649615]
 [0.23636413]
 [0.23652006]
 [0.2361144 ]
 [0.23786638]
 [0.23790929]
 [0.23584387]
 [0.23668919]
 [0.23653771]
 [0.23622876]
 [0.23756344]
 [0.23651011]
 [0.23577579]
 [0.23681405]
 [0.23769424]
 [0.23606984]
 [0.23692281]
 [0.23721445]
 [0.23712756]
 [0.23816026]
 [0.23602488]
 [0.2379128 ]
 [0.23673441]
 [0.23663967]
 [0.23677124]
 [0.23647058]
 [0.23609741]
 [0.23622181]
 [0.23731401]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.9371634  0.         1.         1.
 1.         0.68577788 1.         1.         1.         0.77541599
 1.         0.35787977 0.         1.         0.97407796 0.797122
 1.         0.30536141 1.         1.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.61162922 0.         1.
 1.         1.         1.         0.         0.39226244 0.
 0.         1.         0.         0.39072609 0.         1.
 1.         1.         1.         0.         0.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23632401 1.
  0.         0.         0.        ]
 [0.03386935 0.         0.         0.         0.23649615 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23636413 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23652006 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.2361144  1.
  0.         0.         0.        ]
 [0.         1.         0.         0.         0.23786638 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.23790929 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.23584387 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.01258005 0.23668919 1.
  0.9371634  0.         1.        ]
 [0.         0.09532774 0.         0.         0.23653771 1.
  0.         0.61162922 1.        ]
 [0.         1.         0.         0.         0.23622876 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.23756344 1.
  1.         1.         1.        ]
 [0.         0.         1.         0.42978684 0.23651011 1.
  1.         1.         1.        ]
 [0.         0.53602198 1.         1.         0.23577579 1.
  0.68577788 1.         1.        ]
 [0.         0.         1.         1.         0.23681405 1.
  1.         1.         1.        ]
 [0.         0.         1.         0.91856258 0.23769424 1.
  1.         0.         1.        ]
 [0.         0.         0.24650762 0.42676087 0.23606984 1.
  1.         0.39226244 1.        ]
 [0.         0.10242988 0.         0.         0.23692281 1.
  0.77541599 0.         1.        ]
 [1.         0.         1.         1.         0.23721445 1.
  1.         0.         1.        ]
 [0.58566403 0.         1.         1.         0.23712756 1.
  0.35787977 1.         1.        ]
 [0.         1.         0.64373371 0.87196145 0.23816026 1.
  0.         0.         1.        ]
 [0.42377644 0.         0.43848735 1.         0.23602488 1.
  1.         0.39072609 1.        ]
 [0.         0.         0.         0.         0.2379128  1.
  0.97407796 0.         1.        ]
 [0.         0.         1.         1.         0.23673441 1.
  0.797122   1.         1.        ]
 [0.         0.         1.         1.         0.23663967 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23677124 1.
  0.30536141 1.         1.        ]
 [1.         0.         1.         1.         0.23647058 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.22589494 0.23609741 1.
  1.         0.         1.        ]
 [1.         0.65254351 1.         0.99686289 0.23622181 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.23731401 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 5 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.21742959 0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.69673289 0.
 0.11174686 1.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.12561804
 0.         0.86881032 0.         0.89870862 0.34226902 1.
 1.         0.         0.47017407 1.         0.72072485 0.61056847
 0.51249849 0.         1.         1.         0.         1.
 0.35029399 1.         1.         1.         1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.24979506 0.         0.09523459 0.01038988 1.
 1.         0.         0.5032079  1.         0.86973812 0.
 0.         0.         1.         0.39621682 0.         1.
 0.         1.         1.         0.65783438 1.         0.        ]
wv_lg shape (30, 1)
[[0.23657768]
 [0.23661017]
 [0.23668321]
 [0.23657149]
 [0.23677201]
 [0.23798801]
 [0.23743733]
 [0.2370489 ]
 [0.23739405]
 [0.23764431]
 [0.23782514]
 [0.23762953]
 [0.23667554]
 [0.23718635]
 [0.23754572]
 [0.23657654]
 [0.2382629 ]
 [0.2381409 ]
 [0.23842268]
 [0.23647472]
 [0.23761704]
 [0.23821722]
 [0.23751091]
 [0.23758854]
 [0.23805729]
 [0.23677185]
 [0.23807192]
 [0.23826994]
 [0.23734751]
 [0.23803706]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.61310779
 1.         0.48737949 0.88164751 1.         1.         1.
 0.93067874 1.         0.74733395 1.         0.         1.
 1.         1.         1.         1.         1.         1.
 0.68806392 0.56894082 1.         1.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         1.         0.52084252
 1.         0.         0.83397282 1.         1.         0.36428951
 0.         0.         1.         1.         0.         1.
 1.         1.         0.81119936 1.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23657768 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23661017 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23668321 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23657149 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23677201 1.
  0.         0.         0.        ]
 [0.         1.         0.12561804 0.         0.23798801 1.
  0.61310779 0.         1.        ]
 [0.         0.21742959 0.         0.         0.23743733 1.
  1.         0.         1.        ]
 [0.         0.         0.86881032 0.24979506 0.2370489  1.
  0.48737949 1.         1.        ]
 [0.         0.         0.         0.         0.23739405 1.
  0.88164751 0.         1.        ]
 [0.         0.         0.89870862 0.09523459 0.23764431 1.
  1.         0.         1.        ]
 [0.         0.         0.34226902 0.01038988 0.23782514 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23762953 1.
  1.         0.52084252 1.        ]
 [0.         0.         1.         1.         0.23667554 1.
  0.93067874 1.         1.        ]
 [0.         1.         0.         0.         0.23718635 1.
  1.         0.         1.        ]
 [0.         0.         0.47017407 0.5032079  0.23754572 1.
  0.74733395 0.83397282 1.        ]
 [1.         0.         1.         1.         0.23657654 1.
  1.         1.         1.        ]
 [0.         0.69673289 0.72072485 0.86973812 0.2382629  1.
  0.         1.         1.        ]
 [0.         0.         0.61056847 0.         0.2381409  1.
  1.         0.36428951 1.        ]
 [0.         0.11174686 0.51249849 0.         0.23842268 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.23647472 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.23761704 1.
  1.         1.         1.        ]
 [0.         0.         1.         0.39621682 0.23821722 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.23751091 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.23758854 1.
  1.         1.         1.        ]
 [0.         0.         0.35029399 0.         0.23805729 1.
  0.68806392 1.         1.        ]
 [1.         0.         1.         1.         0.23677185 1.
  0.56894082 1.         1.        ]
 [0.         0.         1.         1.         0.23807192 1.
  1.         0.81119936 1.        ]
 [0.         0.         1.         0.65783438 0.23826994 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23734751 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.23803706 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 6 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.23898162 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         1.         0.
 0.         0.         0.         0.         0.64646438 0.57079309
 1.         0.         0.49223056 0.         0.         0.
 0.         0.         0.68763673 0.78634983 0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.7917872
 0.14791948 0.62850305 1.         0.89942258 0.         0.
 1.         1.         1.         1.         0.         1.
 0.69716728 0.29798015 1.         0.         0.98651389 0.85565622
 1.         1.         0.46902389 1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.46282122
 0.71018423 0.57330933 0.83794766 1.         0.         0.
 0.22159732 1.         1.         1.         0.         1.
 0.         0.5662643  1.         0.         0.97297406 1.
 1.         1.         1.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.23693939]
 [0.23708303]
 [0.23684649]
 [0.23661065]
 [0.23673138]
 [0.23854652]
 [0.23807572]
 [0.23861671]
 [0.23879414]
 [0.2384757 ]
 [0.23824262]
 [0.23875113]
 [0.23883953]
 [0.23875154]
 [0.23823524]
 [0.23872912]
 [0.23871725]
 [0.23791141]
 [0.23844659]
 [0.23824583]
 [0.23820702]
 [0.23902967]
 [0.23874336]
 [0.23801227]
 [0.23777059]
 [0.23863344]
 [0.23742335]
 [0.23866103]
 [0.23814363]
 [0.23833946]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         1.         1.         1.         1.
 0.39781448 1.         0.42850843 1.         1.         0.
 0.0700716  1.         0.         1.         0.78395402 1.
 0.78091918 1.         0.         0.87946125 0.66632068 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.13819003
 0.         0.         0.51871206 0.         0.         0.
 0.         0.33782703 0.         0.31404251 0.         0.
 0.57731434 0.         1.         0.         1.         0.
 1.         1.         0.28263642 0.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23693939 1.
  0.         0.         0.        ]
 [0.23898162 0.         0.         0.         0.23708303 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23684649 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23661065 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23673138 1.
  0.         0.         0.        ]
 [0.         0.         0.7917872  0.46282122 0.23854652 1.
  0.         0.13819003 1.        ]
 [0.         0.         0.14791948 0.71018423 0.23807572 1.
  1.         0.         1.        ]
 [0.         0.         0.62850305 0.57330933 0.23861671 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.83794766 0.23879414 1.
  1.         0.51871206 1.        ]
 [0.         0.         0.89942258 1.         0.2384757  1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.23824262 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.23875113 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.22159732 0.23883953 1.
  0.39781448 0.         1.        ]
 [0.         0.         1.         1.         0.23875154 1.
  1.         0.33782703 1.        ]
 [0.         0.         1.         1.         0.23823524 1.
  0.42850843 0.         1.        ]
 [0.         0.         1.         1.         0.23872912 1.
  1.         0.31404251 1.        ]
 [0.         0.64646438 0.         0.         0.23871725 1.
  1.         0.         1.        ]
 [0.         0.57079309 1.         1.         0.23791141 1.
  0.         0.         1.        ]
 [0.         1.         0.69716728 0.         0.23844659 1.
  0.0700716  0.57731434 1.        ]
 [0.         0.         0.29798015 0.5662643  0.23824583 1.
  1.         0.         1.        ]
 [0.         0.49223056 1.         1.         0.23820702 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.23902967 1.
  1.         0.         1.        ]
 [0.         0.         0.98651389 0.97297406 0.23874336 1.
  0.78395402 1.         1.        ]
 [0.         0.         0.85565622 1.         0.23801227 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.23777059 1.
  0.78091918 1.         1.        ]
 [0.         0.         1.         1.         0.23863344 1.
  1.         1.         1.        ]
 [0.         0.68763673 0.46902389 1.         0.23742335 1.
  0.         0.28263642 1.        ]
 [1.         0.78634983 1.         1.         0.23866103 1.
  0.87946125 0.         1.        ]
 [0.         0.         1.         1.         0.23814363 1.
  0.66632068 1.         1.        ]
 [0.         0.         1.         1.         0.23833946 1.
  1.         0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 7 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.58277588 0.         1.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 1.         0.         1.         0.         1.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.54582697 0.
 0.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.87997895 1.         1.         1.         1.
 0.         0.97839623 1.         1.         1.         0.7944225
 1.         0.76715892 0.31514029 0.         0.56923608 1.
 1.         1.         1.         1.         1.         0.76773822]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.96462451 0.         0.80837663 1.         1.         1.
 0.02043385 0.         1.         1.         1.         0.76531647
 1.         0.57368351 0.         0.         0.03036023 1.
 1.         1.         1.         1.         1.         0.79309846]
wv_lg shape (30, 1)
[[0.2370743 ]
 [0.23712189]
 [0.23710565]
 [0.23705463]
 [0.23713369]
 [0.23959047]
 [0.2389761 ]
 [0.23979125]
 [0.23959545]
 [0.23795554]
 [0.238693  ]
 [0.23854899]
 [0.23838781]
 [0.23978391]
 [0.23955548]
 [0.23967459]
 [0.23901779]
 [0.23811192]
 [0.23854125]
 [0.23898701]
 [0.23926672]
 [0.23855088]
 [0.23918994]
 [0.23909218]
 [0.23914047]
 [0.23954212]
 [0.23857657]
 [0.23876942]
 [0.23878151]
 [0.23866368]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 0.71071079 1.         1.         0.3133258  0.         0.46736403
 1.         0.         0.36247503 0.         0.27240372 0.
 0.         1.         1.         1.         1.         0.65212415
 0.         0.         0.         0.85510475 0.         0.9819286 ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.24558986
 0.         0.         0.83713415 0.07805777 0.73676134 1.
 0.         0.         0.57784932 0.         1.         0.
 1.         0.         0.         0.         0.00449895 1.
 1.         0.82526158 1.         0.         1.         0.33069392]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.2370743  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23712189 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23710565 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23705463 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23713369 1.
  0.         0.         0.        ]
 [0.         0.         1.         1.         0.23959047 1.
  0.         0.24558986 1.        ]
 [0.         0.         1.         0.96462451 0.2389761  1.
  0.71071079 0.         1.        ]
 [0.         0.         0.87997895 0.         0.23979125 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.80837663 0.23959545 1.
  1.         0.83713415 1.        ]
 [0.58277588 1.         1.         1.         0.23795554 1.
  0.3133258  0.07805777 1.        ]
 [0.         0.         1.         1.         0.238693   1.
  0.         0.73676134 1.        ]
 [1.         0.         1.         1.         0.23854899 1.
  0.46736403 1.         1.        ]
 [0.         0.         0.         0.02043385 0.23838781 1.
  1.         0.         1.        ]
 [0.         0.         0.97839623 0.         0.23978391 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.23955548 1.
  0.36247503 0.57784932 1.        ]
 [0.         0.         1.         1.         0.23967459 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.23901779 1.
  0.27240372 1.         1.        ]
 [0.         1.         0.7944225  0.76531647 0.23811192 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.23854125 1.
  0.         1.         1.        ]
 [0.         0.         0.76715892 0.57368351 0.23898701 1.
  1.         0.         1.        ]
 [0.         0.         0.31514029 0.         0.23926672 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.23855088 1.
  1.         0.         1.        ]
 [0.         0.54582697 0.56923608 0.03036023 0.23918994 1.
  1.         0.00449895 1.        ]
 [1.         0.         1.         1.         0.23909218 1.
  0.65212415 1.         1.        ]
 [1.         0.         1.         1.         0.23914047 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23954212 1.
  0.         0.82526158 1.        ]
 [1.         0.         1.         1.         0.23857657 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.23876942 1.
  0.85510475 0.         1.        ]
 [1.         0.         1.         1.         0.23878151 1.
  0.         1.         1.        ]
 [0.         0.         0.76773822 0.79309846 0.23866368 1.
  0.9819286  0.33069392 1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 8 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.75808897
 0.         0.         0.         0.         1.         0.
 0.         0.1229538  0.         0.         0.         0.
 0.         1.         0.         1.         0.         0.26858359
 0.         0.         0.         0.         1.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.84095405 0.84379366 0.         0.0782897
 0.         0.         1.         1.         0.         0.
 0.68110772 1.         1.         0.         0.         0.
 1.         1.         1.         0.8200403  1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.38264849
 0.         0.00679746 1.         0.         0.10960657 0.
 0.         0.         1.         0.         0.         0.
 1.         0.8718528  1.         0.         0.         0.
 1.         1.         1.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.23820548]
 [0.23835974]
 [0.23825725]
 [0.23828988]
 [0.23823112]
 [0.24005905]
 [0.24024645]
 [0.24054088]
 [0.2401918 ]
 [0.24055266]
 [0.23938788]
 [0.24051152]
 [0.24053127]
 [0.24054773]
 [0.24040999]
 [0.24065484]
 [0.24023593]
 [0.24059138]
 [0.23987552]
 [0.24041843]
 [0.23987694]
 [0.24075066]
 [0.24048913]
 [0.24067425]
 [0.24003007]
 [0.2403711 ]
 [0.24010102]
 [0.24008647]
 [0.23968612]
 [0.23869744]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 0.71577894 0.         0.59694132 0.         1.         0.01647468
 0.         0.81007651 0.20728549 0.         0.         1.
 0.77839324 1.         0.81739294 1.         1.         0.79586118
 0.29261509 0.         0.24697196 0.04502831 1.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.28191173
 0.05722393 0.12039051 0.59463825 0.         0.         0.
 0.         0.33379272 0.15381955 0.4561603  0.         0.
 1.         1.         0.88072086 1.         0.1091562  1.
 0.9841881  1.         1.         1.         1.         1.        ]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.23820548 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.23835974 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23825725 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23828988 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23823112 1.
  0.         0.         0.        ]
 [0.         0.75808897 0.         0.38264849 0.24005905 1.
  0.         0.28191173 1.        ]
 [0.         0.         0.         0.         0.24024645 1.
  0.71577894 0.05722393 1.        ]
 [0.         0.         1.         0.00679746 0.24054088 1.
  0.         0.12039051 1.        ]
 [0.         0.         0.84095405 1.         0.2401918  1.
  0.59694132 0.59463825 1.        ]
 [0.         0.         0.84379366 0.         0.24055266 1.
  0.         0.         1.        ]
 [0.         1.         0.         0.10960657 0.23938788 1.
  1.         0.         1.        ]
 [0.         0.         0.0782897  0.         0.24051152 1.
  0.01647468 0.         1.        ]
 [0.         0.         0.         0.         0.24053127 1.
  0.         0.         1.        ]
 [0.         0.1229538  0.         0.         0.24054773 1.
  0.81007651 0.33379272 1.        ]
 [0.         0.         1.         1.         0.24040999 1.
  0.20728549 0.15381955 1.        ]
 [0.         0.         1.         0.         0.24065484 1.
  0.         0.4561603  1.        ]
 [0.         0.         0.         0.         0.24023593 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.24059138 1.
  1.         0.         1.        ]
 [0.         0.         0.68110772 1.         0.23987552 1.
  0.77839324 1.         1.        ]
 [0.         1.         1.         0.8718528  0.24041843 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.23987694 1.
  0.81739294 0.88072086 1.        ]
 [0.         1.         0.         0.         0.24075066 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.24048913 1.
  1.         0.1091562  1.        ]
 [0.         0.26858359 0.         0.         0.24067425 1.
  0.79586118 1.         1.        ]
 [0.         0.         1.         1.         0.24003007 1.
  0.29261509 0.9841881  1.        ]
 [0.         0.         1.         1.         0.2403711  1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.24010102 1.
  0.24697196 1.         1.        ]
 [0.         0.         0.8200403  1.         0.24008647 1.
  0.04502831 1.         1.        ]
 [1.         1.         1.         1.         0.23968612 1.
  1.         1.         1.        ]
 [0.         1.         0.         1.         0.23869744 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 9 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.18339026 0.         0.26529441 1.         0.42585508 0.33468128
 1.         0.         0.         0.         0.59595748 0.
 1.         1.         0.         0.         0.51593664 1.
 0.42585508 1.         1.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.         1.         0.12601086 1.
 0.         0.         0.64272615 0.         1.         0.92428044
 0.         0.0811049  1.         0.37353964 1.         0.65868446
 1.         0.97068988 1.         1.         1.         0.95746944]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.6195139  1.         0.         1.         0.         1.
 0.         0.         0.85912437 0.         0.66423106 0.75066597
 0.         0.         1.         0.75630117 1.         1.
 1.         0.95903489 0.25563927 1.         1.         0.99086099]
wv_lg shape (30, 1)
[[0.23865205]
 [0.23877537]
 [0.23857864]
 [0.23865923]
 [0.23859047]
 [0.24150362]
 [0.24168253]
 [0.24155042]
 [0.24183415]
 [0.24186425]
 [0.24174299]
 [0.24147234]
 [0.24141417]
 [0.24174724]
 [0.24146024]
 [0.2416103 ]
 [0.24178927]
 [0.24156885]
 [0.2411822 ]
 [0.24185631]
 [0.24091575]
 [0.24111468]
 [0.24138689]
 [0.24082864]
 [0.24151651]
 [0.24158452]
 [0.24148001]
 [0.24148447]
 [0.24127776]
 [0.24153709]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.73263929 1.         1.         0.
 0.         1.         0.         1.         1.         0.
 0.62597529 1.         0.         0.09870791 0.         1.
 1.         1.         0.         0.         0.33637414 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.35011754 1.         0.2096044  0.18892387
 0.         0.2260083  0.32724721 0.         0.8292132  1.
 0.         0.         0.8431469  0.34647366 1.         0.58087717
 1.         0.78497159 1.         1.         1.         0.70207572]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23865205 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23877537 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23857864 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23865923 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23859047 1.
  0.         0.         0.        ]
 [0.         0.         1.         1.         0.24150362 1.
  0.         1.         1.        ]
 [0.         0.18339026 1.         0.6195139  0.24168253 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.24155042 1.
  0.         1.         1.        ]
 [0.         0.26529441 0.         0.         0.24183415 1.
  0.73263929 0.35011754 1.        ]
 [0.         1.         1.         1.         0.24186425 1.
  1.         1.         1.        ]
 [0.         0.42585508 0.12601086 0.         0.24174299 1.
  1.         0.2096044  1.        ]
 [0.         0.33468128 1.         1.         0.24147234 1.
  0.         0.18892387 1.        ]
 [0.         1.         0.         0.         0.24141417 1.
  0.         0.         1.        ]
 [0.         0.         0.         0.         0.24174724 1.
  1.         0.2260083  1.        ]
 [0.         0.         0.64272615 0.85912437 0.24146024 1.
  0.         0.32724721 1.        ]
 [0.         0.         0.         0.         0.2416103  1.
  1.         0.         1.        ]
 [0.         0.59595748 1.         0.66423106 0.24178927 1.
  1.         0.8292132  1.        ]
 [0.         0.         0.92428044 0.75066597 0.24156885 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.2411822  1.
  0.62597529 0.         1.        ]
 [0.         1.         0.0811049  0.         0.24185631 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.24091575 1.
  0.         0.8431469  1.        ]
 [0.         0.         0.37353964 0.75630117 0.24111468 1.
  0.09870791 0.34647366 1.        ]
 [1.         0.51593664 1.         1.         0.24138689 1.
  0.         1.         1.        ]
 [0.         1.         0.65868446 1.         0.24082864 1.
  1.         0.58087717 1.        ]
 [0.         0.42585508 1.         1.         0.24151651 1.
  1.         1.         1.        ]
 [0.         1.         0.97068988 0.95903489 0.24158452 1.
  1.         0.78497159 1.        ]
 [0.         1.         1.         0.25563927 0.24148001 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.24148447 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.24127776 1.
  0.33637414 1.         1.        ]
 [0.         0.         0.95746944 0.99086099 0.24153709 1.
  0.         0.70207572 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 10 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.980809
 0.50763536 0.         0.         0.18157936 0.28644846 0.08663097
 0.42781502 0.13574549 0.         0.28644846 0.         0.
 0.54454732 0.         0.         1.         0.         0.
 0.         0.50763536 0.         0.         0.         0.24561963]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.18677205 0.19925942 0.         0.87817485
 0.         1.         0.         0.99524826 0.25395271 1.
 0.15579553 0.         0.62892111 0.         1.         0.12713657
 0.81306798 0.         0.37505403 1.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.         0.
 0.         0.32505892 0.         0.73814381 0.         1.
 0.         0.         0.00737499 0.         0.43936537 0.
 0.07320788 0.         0.10798327 0.43120352 0.         0.71313313]
wv_lg shape (30, 1)
[[0.23978959]
 [0.23964348]
 [0.23969028]
 [0.23972715]
 [0.23971953]
 [0.24276451]
 [0.24323975]
 [0.24220183]
 [0.24344512]
 [0.24295888]
 [0.24251511]
 [0.24294744]
 [0.24315836]
 [0.24338372]
 [0.24314828]
 [0.24266716]
 [0.24296649]
 [0.24218516]
 [0.24281963]
 [0.24326696]
 [0.24294724]
 [0.24253873]
 [0.24304026]
 [0.24320641]
 [0.24341755]
 [0.24289709]
 [0.24313473]
 [0.24300982]
 [0.24336543]
 [0.24304228]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.195152
 1.         0.12615325 1.         0.         0.         0.
 1.         0.         1.         0.         0.79211124 0.
 1.         0.57316913 0.26342563 1.         0.         1.
 1.         1.         1.         1.         0.94510707 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.52886906 0.         0.         1.
 0.91442111 1.         0.         0.03230448 0.38481108 1.
 1.         0.         1.         0.         1.         0.5937953
 0.9881991  0.         0.         0.75388947 0.         0.97878443]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.23978959 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23964348 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23969028 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23972715 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.23971953 1.
  0.         0.         0.        ]
 [0.         0.980809   0.         0.         0.24276451 1.
  0.195152   0.         1.        ]
 [0.         0.50763536 0.         0.         0.24323975 1.
  1.         0.         1.        ]
 [1.         0.         1.         1.         0.24220183 1.
  0.12615325 1.         1.        ]
 [0.         0.         0.18677205 0.         0.24344512 1.
  1.         0.52886906 1.        ]
 [0.         0.18157936 0.19925942 0.         0.24295888 1.
  0.         0.         1.        ]
 [0.         0.28644846 0.         0.         0.24251511 1.
  0.         0.         1.        ]
 [0.         0.08663097 0.87817485 0.         0.24294744 1.
  0.         1.         1.        ]
 [0.         0.42781502 0.         0.         0.24315836 1.
  1.         0.91442111 1.        ]
 [0.         0.13574549 1.         0.32505892 0.24338372 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.24314828 1.
  1.         0.         1.        ]
 [0.         0.28644846 0.99524826 0.73814381 0.24266716 1.
  0.         0.03230448 1.        ]
 [0.         0.         0.25395271 0.         0.24296649 1.
  0.79211124 0.38481108 1.        ]
 [0.         0.         1.         1.         0.24218516 1.
  0.         1.         1.        ]
 [0.         0.54454732 0.15579553 0.         0.24281963 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.24326696 1.
  0.57316913 0.         1.        ]
 [0.         0.         0.62892111 0.00737499 0.24294724 1.
  0.26342563 1.         1.        ]
 [0.         1.         0.         0.         0.24253873 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.43936537 0.24304026 1.
  0.         1.         1.        ]
 [0.         0.         0.12713657 0.         0.24320641 1.
  1.         0.5937953  1.        ]
 [0.         0.         0.81306798 0.07320788 0.24341755 1.
  1.         0.9881991  1.        ]
 [0.         0.50763536 0.         0.         0.24289709 1.
  1.         0.         1.        ]
 [0.         0.         0.37505403 0.10798327 0.24313473 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.43120352 0.24300982 1.
  1.         0.75388947 1.        ]
 [0.         0.         0.         0.         0.24336543 1.
  0.94510707 0.         1.        ]
 [0.         0.24561963 1.         0.71313313 0.24304228 1.
  0.         0.97878443 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 11 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.97722334 1.         1.         0.         1.         1.
 0.25473785 1.         0.09205249 0.         0.         1.
 0.48740107 1.         1.         0.03655475 1.         1.
 1.         0.58373739 0.99572185 1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.87278415
 0.51668189 1.         1.         0.         1.         1.
 0.         1.         0.         0.         0.         1.
 0.         1.         1.         0.         1.         1.
 1.         0.24606829 0.85767294 1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.24070856]
 [0.24075074]
 [0.24084668]
 [0.24069952]
 [0.24076974]
 [0.24459038]
 [0.24462902]
 [0.2442045 ]
 [0.24465895]
 [0.24444124]
 [0.24517635]
 [0.24443986]
 [0.24508076]
 [0.24445175]
 [0.24474496]
 [0.24431754]
 [0.24496269]
 [0.24410021]
 [0.24541288]
 [0.24438731]
 [0.24443037]
 [0.24411153]
 [0.24486901]
 [0.24445895]
 [0.24464274]
 [0.24474074]
 [0.24463436]
 [0.24365524]
 [0.2445679 ]
 [0.24419225]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.06730875 0.         1.         0.         0.12951743
 1.         0.81174473 0.         1.         0.74862774 0.
 0.15010919 0.49156268 0.         1.         0.8879819  0.27922149
 0.34992056 0.38396298 0.3435007  0.         0.277035   0.12337272]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.26583076 0.59313126 1.         0.         0.95872522 1.
 0.76740678 1.         0.83486432 0.         0.         1.
 0.60753784 1.         0.59457909 0.84574903 1.         1.
 1.         0.44641732 0.38785199 1.         1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.24070856 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24075074 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24084668 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24069952 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24076974 1.
  0.         0.         0.        ]
 [0.         0.         1.         0.87278415 0.24459038 1.
  1.         1.         1.        ]
 [0.         0.         0.97722334 0.51668189 0.24462902 1.
  0.         0.26583076 1.        ]
 [0.         0.         1.         1.         0.2442045  1.
  0.06730875 0.59313126 1.        ]
 [0.         0.         1.         1.         0.24465895 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.24444124 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.24517635 1.
  0.         0.95872522 1.        ]
 [0.         0.         1.         1.         0.24443986 1.
  0.12951743 1.         1.        ]
 [0.         0.         0.25473785 0.         0.24508076 1.
  1.         0.76740678 1.        ]
 [0.         0.         1.         1.         0.24445175 1.
  0.81174473 1.         1.        ]
 [0.         0.         0.09205249 0.         0.24474496 1.
  0.         0.83486432 1.        ]
 [0.         1.         0.         0.         0.24431754 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.24496269 1.
  0.74862774 0.         1.        ]
 [1.         0.         1.         1.         0.24410021 1.
  0.         1.         1.        ]
 [0.         0.         0.48740107 0.         0.24541288 1.
  0.15010919 0.60753784 1.        ]
 [0.         0.         1.         1.         0.24438731 1.
  0.49156268 1.         1.        ]
 [0.         0.         1.         1.         0.24443037 1.
  0.         0.59457909 1.        ]
 [0.         0.         0.03655475 0.         0.24411153 1.
  1.         0.84574903 1.        ]
 [0.         0.         1.         1.         0.24486901 1.
  0.8879819  1.         1.        ]
 [0.         0.         1.         1.         0.24445895 1.
  0.27922149 1.         1.        ]
 [0.         0.         1.         1.         0.24464274 1.
  0.34992056 1.         1.        ]
 [0.         0.         0.58373739 0.24606829 0.24474074 1.
  0.38396298 0.44641732 1.        ]
 [0.         0.         0.99572185 0.85767294 0.24463436 1.
  0.3435007  0.38785199 1.        ]
 [0.         0.         1.         1.         0.24365524 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.2445679  1.
  0.277035   1.         1.        ]
 [0.         0.         1.         1.         0.24419225 1.
  0.12337272 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 12 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.3941946 0.        1.        1.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.        0.        0.        0.        0.        0.
 0.        0.       ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.49695482 0.12369281 1.         0.
 1.         0.         0.         1.         0.         0.
 0.43478708 0.         0.         1.         0.         0.
 1.         1.         0.12369281 0.         0.43478708 1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.82545874
 0.89540212 0.45591664 1.         0.         0.97052485 0.
 1.         0.89165687 1.         0.         1.         0.59600745
 0.         0.         0.17945674 0.         1.         1.
 1.         0.         0.43945473 1.         0.82921985 1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.55682227
 0.36021038 0.         1.         0.         1.         0.
 1.         0.75801073 1.         0.         1.         0.00392091
 0.         0.         0.         0.12914975 1.         1.
 0.58257383 0.         0.90477515 0.87411694 0.67448959 1.        ]
wv_lg shape (30, 1)
[[0.24219616]
 [0.24217534]
 [0.24213799]
 [0.24208987]
 [0.24201815]
 [0.246423  ]
 [0.24693294]
 [0.24682594]
 [0.24651821]
 [0.24675942]
 [0.24470911]
 [0.24681612]
 [0.24651564]
 [0.24634836]
 [0.24623103]
 [0.24622614]
 [0.24662871]
 [0.24706903]
 [0.24654819]
 [0.2469885 ]
 [0.24675937]
 [0.24640268]
 [0.24634172]
 [0.24643473]
 [0.24711773]
 [0.24647064]
 [0.24651963]
 [0.24631204]
 [0.24639562]
 [0.24577933]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.         0.         1.         0.94811449 0.28582472
 0.59699106 0.03745706 0.         0.81975801 0.12294499 0.19452782
 0.83215218 0.01150597 0.11682142 1.         0.         0.
 0.         1.         0.64312652 0.70965765 0.50418947 0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.48595528
 1.         0.32337037 0.40539971 0.         0.10020604 0.
 1.         0.62656031 1.         0.         1.         0.35123915
 0.         0.         0.         0.         1.         1.
 1.         0.         0.         1.         0.77814865 1.        ]
xy shape: (30, 9)
[[0.3941946  0.         0.         0.         0.24219616 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24217534 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.24213799 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.24208987 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24201815 1.
  0.         0.         0.        ]
 [0.         0.         0.82545874 0.55682227 0.246423   1.
  0.         0.48595528 1.        ]
 [0.         1.         0.89540212 0.36021038 0.24693294 1.
  1.         1.         1.        ]
 [0.         0.         0.45591664 0.         0.24682594 1.
  0.         0.32337037 1.        ]
 [0.         0.49695482 1.         1.         0.24651821 1.
  0.         0.40539971 1.        ]
 [0.         0.12369281 0.         0.         0.24675942 1.
  1.         0.         1.        ]
 [0.         1.         0.97052485 1.         0.24470911 1.
  0.94811449 0.10020604 1.        ]
 [0.         0.         0.         0.         0.24681612 1.
  0.28582472 0.         1.        ]
 [0.         1.         1.         1.         0.24651564 1.
  0.59699106 1.         1.        ]
 [0.         0.         0.89165687 0.75801073 0.24634836 1.
  0.03745706 0.62656031 1.        ]
 [0.         0.         1.         1.         0.24623103 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.24622614 1.
  0.81975801 0.         1.        ]
 [0.         0.         1.         1.         0.24662871 1.
  0.12294499 1.         1.        ]
 [0.         0.         0.59600745 0.00392091 0.24706903 1.
  0.19452782 0.35123915 1.        ]
 [0.         0.43478708 0.         0.         0.24654819 1.
  0.83215218 0.         1.        ]
 [0.         0.         0.         0.         0.2469885  1.
  0.01150597 0.         1.        ]
 [0.         0.         0.17945674 0.         0.24675937 1.
  0.11682142 0.         1.        ]
 [0.         1.         0.         0.12914975 0.24640268 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.24634172 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.24643473 1.
  0.         1.         1.        ]
 [0.         1.         1.         0.58257383 0.24711773 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.24647064 1.
  1.         0.         1.        ]
 [0.         0.12369281 0.43945473 0.90477515 0.24651963 1.
  0.64312652 0.         1.        ]
 [0.         0.         1.         0.87411694 0.24631204 1.
  0.70965765 1.         1.        ]
 [0.         0.43478708 0.82921985 0.67448959 0.24639562 1.
  0.50418947 0.77814865 1.        ]
 [0.         1.         1.         1.         0.24577933 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 13 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.39555143 1.         0.30238509 1.         1.         0.
 0.52002211 0.30238509 1.         0.60039582 0.93083101 0.29287541
 1.         0.         0.         1.         0.48629058 0.
 0.         0.20793559 1.         0.         1.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.23239584
 1.         0.         0.         0.         0.47726974 0.4245693
 0.76784437 0.         1.         0.60676298 0.76865222 0.
 0.30857694 0.12784081 0.         0.77587229 1.         1.
 1.         0.         0.80506939 1.         0.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.01854194
 1.         0.         0.11340894 0.         0.         0.28674739
 1.         0.00537748 1.         0.70061058 0.36643335 0.
 0.39176375 0.         0.         0.27730005 0.98106666 1.
 1.         0.         0.         1.         0.         1.        ]
wv_lg shape (30, 1)
[[0.24359333]
 [0.24359495]
 [0.24341011]
 [0.2435194 ]
 [0.24358094]
 [0.24864084]
 [0.24857013]
 [0.2492215 ]
 [0.24854722]
 [0.24811144]
 [0.24924041]
 [0.24834301]
 [0.24775796]
 [0.24885786]
 [0.24892859]
 [0.24789311]
 [0.24891751]
 [0.24882986]
 [0.24881136]
 [0.24938717]
 [0.24888015]
 [0.24912665]
 [0.24880606]
 [0.24834439]
 [0.24844936]
 [0.24883217]
 [0.24881871]
 [0.24849161]
 [0.24945666]
 [0.24789316]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         1.         1.         0.         0.02007613
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         0.91190846
 0.42922523 1.         0.         0.62316326 0.82382617 0.20050809]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.14780309
 1.         0.         0.         0.72935879 1.         0.40215496
 0.31109678 0.         1.         0.28435012 1.         0.
 0.10420319 0.31981237 0.         1.         1.         1.
 1.         0.         0.98086344 1.         0.13944015 1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.24359333 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24359495 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24341011 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.2435194  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24358094 1.
  0.         0.         0.        ]
 [0.         0.         0.23239584 0.01854194 0.24864084 1.
  0.         0.14780309 1.        ]
 [0.         0.39555143 1.         1.         0.24857013 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.2492215  1.
  1.         0.         1.        ]
 [0.         0.30238509 0.         0.11340894 0.24854722 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.24811144 1.
  1.         0.72935879 1.        ]
 [0.         1.         0.47726974 0.         0.24924041 1.
  0.         1.         1.        ]
 [0.         0.         0.4245693  0.28674739 0.24834301 1.
  0.02007613 0.40215496 1.        ]
 [0.         0.52002211 0.76784437 1.         0.24775796 1.
  1.         0.31109678 1.        ]
 [0.         0.30238509 0.         0.00537748 0.24885786 1.
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.24892859 1.
  1.         1.         1.        ]
 [0.         0.60039582 0.60676298 0.70061058 0.24789311 1.
  1.         0.28435012 1.        ]
 [0.         0.93083101 0.76865222 0.36643335 0.24891751 1.
  1.         1.         1.        ]
 [0.         0.29287541 0.         0.         0.24882986 1.
  1.         0.         1.        ]
 [0.         1.         0.30857694 0.39176375 0.24881136 1.
  1.         0.10420319 1.        ]
 [0.         0.         0.12784081 0.         0.24938717 1.
  1.         0.31981237 1.        ]
 [0.         0.         0.         0.         0.24888015 1.
  1.         0.         1.        ]
 [0.         1.         0.77587229 0.27730005 0.24912665 1.
  1.         1.         1.        ]
 [0.         0.48629058 1.         0.98106666 0.24880606 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.24834439 1.
  0.91190846 1.         1.        ]
 [0.         0.         1.         1.         0.24844936 1.
  0.42922523 1.         1.        ]
 [0.         0.20793559 0.         0.         0.24883217 1.
  1.         0.         1.        ]
 [0.         1.         0.80506939 0.         0.24881871 1.
  0.         0.98086344 1.        ]
 [0.         0.         1.         1.         0.24849161 1.
  0.62316326 1.         1.        ]
 [0.         1.         0.         0.         0.24945666 1.
  0.82382617 0.13944015 1.        ]
 [1.         0.         1.         1.         0.24789316 1.
  0.20050809 1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 14 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.13264854 0.         0.         0.         0.
 1.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         0.17631    0.         0.37422127 0.         1.
 0.07815857 0.970569   0.         0.         0.87244628 1.
 0.         0.         0.         0.         1.         0.9253832
 0.         1.         0.         1.         0.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.         1.         0.56033167 1.         1.
 0.21754849 0.         0.         0.84866304 0.79758146 0.
 0.30410498 1.         0.98997798 1.         0.43330929 0.
 0.84018779 1.         1.         1.         0.         0.74584725]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.01500985 1.         0.9057592  1.         1.
 0.27274541 0.         0.         1.         0.79362328 0.1780089
 0.20210033 1.         0.94975358 1.         0.70254408 0.
 1.         0.88757601 1.         1.         0.         0.85178799]
wv_lg shape (30, 1)
[[0.2452623 ]
 [0.24538445]
 [0.24532873]
 [0.24531208]
 [0.24536494]
 [0.25121549]
 [0.25139999]
 [0.25168451]
 [0.25011671]
 [0.25141093]
 [0.25105743]
 [0.25014639]
 [0.25131847]
 [0.25135465]
 [0.25141207]
 [0.25115004]
 [0.2514628 ]
 [0.25146803]
 [0.25145669]
 [0.2505163 ]
 [0.25154323]
 [0.25111987]
 [0.25241764]
 [0.25136301]
 [0.25056264]
 [0.25218957]
 [0.25098276]
 [0.25148444]
 [0.25189047]
 [0.25112167]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.26658698
 0.         0.37083156 0.09394749 0.54459664 0.         0.
 1.         1.         0.80875441 0.         0.         0.85604537
 0.23036974 0.         1.         0.         0.06993818 0.80492614
 0.         0.         0.79883492 0.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.         0.81631102 0.         1.         1.
 0.21774304 0.         0.         0.         0.08806222 0.
 0.         0.15434931 0.692508   0.48636294 1.         0.
 0.         0.67163024 0.99315082 0.1034178  0.         0.38569396]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.2452623  1.
  0.         0.         0.        ]
 [0.13264854 0.         0.         0.         0.24538445 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24532873 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24531208 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.24536494 1.
  0.         0.         0.        ]
 [0.         0.         1.         1.         0.25121549 1.
  0.26658698 1.         1.        ]
 [1.         1.         1.         1.         0.25139999 1.
  0.         1.         1.        ]
 [0.         0.17631    0.         0.01500985 0.25168451 1.
  0.37083156 0.         1.        ]
 [0.         0.         1.         1.         0.25011671 1.
  0.09394749 0.81631102 1.        ]
 [0.         0.37422127 0.56033167 0.9057592  0.25141093 1.
  0.54459664 0.         1.        ]
 [0.         0.         1.         1.         0.25105743 1.
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.25014639 1.
  0.         1.         1.        ]
 [0.         0.07815857 0.21754849 0.27274541 0.25131847 1.
  1.         0.21774304 1.        ]
 [0.         0.970569   0.         0.         0.25135465 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.25141207 1.
  0.80875441 0.         1.        ]
 [0.         0.         0.84866304 1.         0.25115004 1.
  0.         0.         1.        ]
 [0.         0.87244628 0.79758146 0.79362328 0.2514628  1.
  0.         0.08806222 1.        ]
 [0.         1.         0.         0.1780089  0.25146803 1.
  0.85604537 0.         1.        ]
 [0.         0.         0.30410498 0.20210033 0.25145669 1.
  0.23036974 0.         1.        ]
 [0.         0.         1.         1.         0.2505163  1.
  0.         0.15434931 1.        ]
 [0.         0.         0.98997798 0.94975358 0.25154323 1.
  1.         0.692508   1.        ]
 [0.         0.         1.         1.         0.25111987 1.
  0.         0.48636294 1.        ]
 [0.         1.         0.43330929 0.70254408 0.25241764 1.
  0.06993818 1.         1.        ]
 [0.         0.9253832  0.         0.         0.25136301 1.
  0.80492614 0.         1.        ]
 [0.         0.         0.84018779 1.         0.25056264 1.
  0.         0.         1.        ]
 [0.         1.         1.         0.88757601 0.25218957 1.
  0.         0.67163024 1.        ]
 [0.         0.         1.         1.         0.25098276 1.
  0.79883492 0.99315082 1.        ]
 [0.         1.         1.         1.         0.25148444 1.
  0.         0.1034178  1.        ]
 [0.         0.         0.         0.         0.25189047 1.
  1.         0.         1.        ]
 [0.         1.         0.74584725 0.85178799 0.25112167 1.
  1.         0.38569396 1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 15 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.25203502 0.         0.         0.         0.86361631
 1.         0.         0.         0.         0.         0.
 0.         0.57539066 0.         0.         0.86361631 1.
 0.53302259 0.         0.01666284 0.         0.31945939 0.17292915]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.35271117
 0.         1.         0.         0.2881427  0.         1.
 1.         1.         0.36135206 0.03404074 0.55890313 0.04110026
 0.         0.67287172 1.         1.         1.         0.25734866
 0.99366167 0.5958029  0.0890854  0.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.48644527 0.         0.         0.         0.84777909
 1.         1.         0.74553518 0.0045165  0.61366814 0.3574351
 0.         0.36259726 0.32582815 1.         0.72115728 0.04491126
 0.         0.2459386  0.38956217 0.06842817 0.         0.        ]
wv_lg shape (30, 1)
[[0.24669166]
 [0.24661276]
 [0.24674608]
 [0.24664276]
 [0.24668491]
 [0.25482179]
 [0.25399789]
 [0.25378942]
 [0.25333603]
 [0.25237967]
 [0.25397478]
 [0.25441012]
 [0.25352685]
 [0.2528817 ]
 [0.25272809]
 [0.2532847 ]
 [0.2530769 ]
 [0.25379229]
 [0.25491281]
 [0.25276247]
 [0.2531662 ]
 [0.25380734]
 [0.25341433]
 [0.25271995]
 [0.25424395]
 [0.25327756]
 [0.2527287 ]
 [0.25442002]
 [0.25402279]
 [0.25336432]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.44443349
 1.         0.22140548 0.89658247 0.01119444 1.         0.83521871
 0.         0.2491661  1.         0.7069483  0.32376967 1.
 0.74609255 1.         1.         0.03145381 0.96454263 0.
 1.         1.         0.28125566 0.65630435 0.         0.85139968]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.19794146
 0.         1.         0.         0.         0.         1.
 0.         0.26947056 0.         0.         0.         0.
 0.         0.59900602 1.         1.         1.         0.
 1.         0.33765265 0.         0.         0.10270684 0.        ]
xy shape: (30, 9)
[[0.45980966 0.         0.         0.         0.24669166 1.
  0.         0.         0.        ]
 [0.45980966 0.         0.         0.         0.24661276 1.
  0.         0.         0.        ]
 [0.45980966 0.         0.         0.         0.24674608 1.
  0.         0.         0.        ]
 [0.45980966 0.         0.         0.         0.24664276 1.
  0.         0.         0.        ]
 [0.45980966 0.         0.         0.         0.24668491 1.
  0.         0.         0.        ]
 [0.45980966 0.         0.35271117 0.         0.25482179 1.
  0.44443349 0.19794146 1.        ]
 [0.45980966 0.         0.         0.         0.25399789 1.
  1.         0.         1.        ]
 [0.45980966 0.25203502 1.         0.48644527 0.25378942 1.
  0.22140548 1.         1.        ]
 [0.45980966 0.         0.         0.         0.25333603 1.
  0.89658247 0.         1.        ]
 [0.45980966 0.         0.2881427  0.         0.25237967 1.
  0.01119444 0.         1.        ]
 [0.45980966 0.         0.         0.         0.25397478 1.
  1.         0.         1.        ]
 [0.45980966 0.86361631 1.         0.84777909 0.25441012 1.
  0.83521871 1.         1.        ]
 [0.45980966 1.         1.         1.         0.25352685 1.
  0.         0.         1.        ]
 [0.45980966 0.         1.         1.         0.2528817  1.
  0.2491661  0.26947056 1.        ]
 [0.45980966 0.         0.36135206 0.74553518 0.25272809 1.
  1.         0.         1.        ]
 [0.45980966 0.         0.03404074 0.0045165  0.2532847  1.
  0.7069483  0.         1.        ]
 [0.45980966 0.         0.55890313 0.61366814 0.2530769  1.
  0.32376967 0.         1.        ]
 [0.45980966 0.         0.04110026 0.3574351  0.25379229 1.
  1.         0.         1.        ]
 [0.45980966 0.         0.         0.         0.25491281 1.
  0.74609255 0.         1.        ]
 [0.45980966 0.57539066 0.67287172 0.36259726 0.25276247 1.
  1.         0.59900602 1.        ]
 [0.45980966 0.         1.         0.32582815 0.2531662  1.
  1.         1.         1.        ]
 [0.45980966 0.         1.         1.         0.25380734 1.
  0.03145381 1.         1.        ]
 [0.45980966 0.86361631 1.         0.72115728 0.25341433 1.
  0.96454263 1.         1.        ]
 [0.45980966 1.         0.25734866 0.04491126 0.25271995 1.
  0.         0.         1.        ]
 [0.45980966 0.53302259 0.99366167 0.         0.25424395 1.
  1.         1.         1.        ]
 [0.45980966 0.         0.5958029  0.2459386  0.25327756 1.
  1.         0.33765265 1.        ]
 [0.45980966 0.01666284 0.0890854  0.38956217 0.2527287  1.
  0.28125566 0.         1.        ]
 [0.45980966 0.         0.         0.06842817 0.25442002 1.
  0.65630435 0.         1.        ]
 [0.45980966 0.31945939 0.         0.         0.25402279 1.
  0.         0.10270684 1.        ]
 [0.45980966 0.17292915 0.         0.         0.25336432 1.
  0.85139968 0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 16 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.94990178 1.         0.43770576 0.         0.         0.
 0.         0.         0.         1.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.06420677 0.         0.5381247  0.         0.40373548
 1.         0.         0.         0.         0.         0.
 1.         0.         0.15722165 1.         0.59706911 1.
 0.         0.15722165 0.         0.         0.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.8739664  0.         1.         0.06455017 1.
 1.         0.         0.25560797 0.91669517 1.         0.01977735
 1.         1.         1.         1.         0.10721175 0.
 0.12633163 1.         0.7523707  1.         1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.83812337 0.         1.         0.         1.
 0.5669535  0.         0.         0.79747742 1.         0.
 1.         1.         1.         1.         0.         0.
 0.10281665 0.82649419 0.55336621 1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.25018871]
 [0.25014939]
 [0.25013436]
 [0.25024198]
 [0.25007407]
 [0.2570202 ]
 [0.25761372]
 [0.25713965]
 [0.25797136]
 [0.25687576]
 [0.25712167]
 [0.25621156]
 [0.25761251]
 [0.2570854 ]
 [0.25726738]
 [0.25745939]
 [0.25722067]
 [0.25718823]
 [0.25826597]
 [0.25750451]
 [0.2578724 ]
 [0.25673186]
 [0.25807487]
 [0.2562481 ]
 [0.2579916 ]
 [0.25793437]
 [0.25766441]
 [0.25716006]
 [0.25747776]
 [0.25733526]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.39772147 1.         0.9972904  0.
 0.609672   1.         0.95615062 0.87010936 0.78856492 1.
 0.92101557 0.24735322 0.65602218 0.67195444 0.14766718 1.
 1.         0.75468133 0.53840025 1.         0.43948697 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.81454035
 0.         0.62969783 0.         1.         0.37650538 1.
 1.         0.         0.48642053 0.90390673 1.         0.19622955
 1.         1.         1.         1.         0.32822517 0.
 0.22571409 1.         0.84494826 1.         0.83525875 1.        ]
xy shape: (30, 9)
[[0.94990178 0.         0.         0.         0.25018871 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.25014939 1.
  0.         0.         0.        ]
 [0.43770576 0.         0.         0.         0.25013436 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.25024198 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.25007407 1.
  0.         0.         0.        ]
 [0.         0.         1.         1.         0.2570202  1.
  1.         0.81454035 1.        ]
 [0.         0.         0.         0.         0.25761372 1.
  1.         0.         1.        ]
 [0.         0.06420677 0.8739664  0.83812337 0.25713965 1.
  1.         0.62969783 1.        ]
 [0.         0.         0.         0.         0.25797136 1.
  0.39772147 0.         1.        ]
 [1.         0.5381247  1.         1.         0.25687576 1.
  1.         1.         1.        ]
 [0.         0.         0.06455017 0.         0.25712167 1.
  0.9972904  0.37650538 1.        ]
 [0.         0.40373548 1.         1.         0.25621156 1.
  0.         1.         1.        ]
 [0.         1.         1.         0.5669535  0.25761251 1.
  0.609672   1.         1.        ]
 [0.         0.         0.         0.         0.2570854  1.
  1.         0.         1.        ]
 [0.         0.         0.25560797 0.         0.25726738 1.
  0.95615062 0.48642053 1.        ]
 [0.         0.         0.91669517 0.79747742 0.25745939 1.
  0.87010936 0.90390673 1.        ]
 [0.         0.         1.         1.         0.25722067 1.
  0.78856492 1.         1.        ]
 [0.         0.         0.01977735 0.         0.25718823 1.
  1.         0.19622955 1.        ]
 [0.         1.         1.         1.         0.25826597 1.
  0.92101557 1.         1.        ]
 [0.         0.         1.         1.         0.25750451 1.
  0.24735322 1.         1.        ]
 [0.         0.15722165 1.         1.         0.2578724  1.
  0.65602218 1.         1.        ]
 [0.         1.         1.         1.         0.25673186 1.
  0.67195444 1.         1.        ]
 [0.         0.59706911 0.10721175 0.         0.25807487 1.
  0.14766718 0.32822517 1.        ]
 [0.         1.         0.         0.         0.2562481  1.
  1.         0.         1.        ]
 [0.         0.         0.12633163 0.10281665 0.2579916  1.
  1.         0.22571409 1.        ]
 [0.         0.15722165 1.         0.82649419 0.25793437 1.
  0.75468133 1.         1.        ]
 [0.         0.         0.7523707  0.55336621 0.25766441 1.
  0.53840025 0.84494826 1.        ]
 [0.         0.         1.         1.         0.25716006 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.25747776 1.
  0.43948697 0.83525875 1.        ]
 [0.         1.         1.         1.         0.25733526 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 17 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.56507609 0.         0.         0.         1.
 0.         0.         0.28119888 0.         0.         0.
 0.30343532 0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.12931623 0.         1.         1.         0.
 0.         1.         0.         1.         0.         0.24408195
 0.         0.03709167 1.         1.         0.         0.
 0.82811805 0.         1.         1.         0.74718632 1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.3500719
 0.         0.37699311 0.         1.         0.28026235 0.43584438
 0.         1.         0.         0.5735192  0.         0.06469081
 0.         0.         1.         1.         0.         0.
 1.         0.         1.         1.         0.64730679 1.        ]
wv_lg shape (30, 1)
[[0.25315501]
 [0.25285846]
 [0.25282784]
 [0.25308294]
 [0.25293938]
 [0.26048101]
 [0.26121844]
 [0.25913947]
 [0.2614019 ]
 [0.26051749]
 [0.26113551]
 [0.26054176]
 [0.26111028]
 [0.26062937]
 [0.26157165]
 [0.26065497]
 [0.26118576]
 [0.26069677]
 [0.26090239]
 [0.2615838 ]
 [0.25975361]
 [0.2590473 ]
 [0.26120612]
 [0.26100983]
 [0.2610354 ]
 [0.2612717 ]
 [0.26159545]
 [0.26053074]
 [0.25987561]
 [0.2606678 ]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.51118367
 1.         0.20479284 1.         0.04457615 0.99423711 1.
 0.59854602 1.         0.41308214 0.30317196 0.99928686 1.
 0.60254119 1.         0.46547658 0.02872604 1.         0.04137638
 0.48609475 0.         0.15450658 0.93279997 1.         0.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         1.         0.
 0.19189381 1.         0.         1.         0.         0.41017036
 0.         0.5256396  1.         1.         0.         0.01718027
 0.28515179 0.         1.         1.         0.83542593 1.        ]
xy shape: (30, 9)
[[0.47372367 0.         0.         0.         0.25315501 1.
  0.         0.         0.        ]
 [0.47372367 0.         0.         0.         0.25285846 1.
  0.         0.         0.        ]
 [0.47372367 0.         0.         0.         0.25282784 1.
  0.         0.         0.        ]
 [0.47372367 0.         0.         0.         0.25308294 1.
  0.         0.         0.        ]
 [0.47372367 0.         0.         0.         0.25293938 1.
  0.         0.         0.        ]
 [0.47372367 0.         0.         0.3500719  0.26048101 1.
  0.51118367 0.         1.        ]
 [0.47372367 0.         0.         0.         0.26121844 1.
  1.         0.         1.        ]
 [0.47372367 0.56507609 0.12931623 0.37699311 0.25913947 1.
  0.20479284 0.         1.        ]
 [0.47372367 0.         0.         0.         0.2614019  1.
  1.         0.         1.        ]
 [0.47372367 0.         1.         1.         0.26051749 1.
  0.04457615 1.         1.        ]
 [0.47372367 0.         1.         0.28026235 0.26113551 1.
  0.99423711 1.         1.        ]
 [0.47372367 1.         0.         0.43584438 0.26054176 1.
  1.         0.         1.        ]
 [0.47372367 0.         0.         0.         0.26111028 1.
  0.59854602 0.19189381 1.        ]
 [0.47372367 0.         1.         1.         0.26062937 1.
  1.         1.         1.        ]
 [0.47372367 0.28119888 0.         0.         0.26157165 1.
  0.41308214 0.         1.        ]
 [0.47372367 0.         1.         0.5735192  0.26065497 1.
  0.30317196 1.         1.        ]
 [0.47372367 0.         0.         0.         0.26118576 1.
  0.99928686 0.         1.        ]
 [0.47372367 0.         0.24408195 0.06469081 0.26069677 1.
  1.         0.41017036 1.        ]
 [0.47372367 0.30343532 0.         0.         0.26090239 1.
  0.60254119 0.         1.        ]
 [0.47372367 0.         0.03709167 0.         0.2615838  1.
  1.         0.5256396  1.        ]
 [0.47372367 0.         1.         1.         0.25975361 1.
  0.46547658 1.         1.        ]
 [0.47372367 0.         1.         1.         0.2590473  1.
  0.02872604 1.         1.        ]
 [0.47372367 0.         0.         0.         0.26120612 1.
  1.         0.         1.        ]
 [0.47372367 0.         0.         0.         0.26100983 1.
  0.04137638 0.01718027 1.        ]
 [0.47372367 0.         0.82811805 1.         0.2610354  1.
  0.48609475 0.28515179 1.        ]
 [0.47372367 0.         0.         0.         0.2612717  1.
  0.         0.         1.        ]
 [0.47372367 1.         1.         1.         0.26159545 1.
  0.15450658 1.         1.        ]
 [0.47372367 0.         1.         1.         0.26053074 1.
  0.93279997 1.         1.        ]
 [0.47372367 0.         0.74718632 0.64730679 0.25987561 1.
  1.         0.83542593 1.        ]
 [0.47372367 0.         1.         1.         0.2606678  1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 18 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         1.         0.         0.03250273 1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         1.
 1.         0.         0.         0.71328923 0.08287956 1.
 0.31389061 1.         0.03456697 1.         0.         1.
 0.         0.         0.08287956 1.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.27961206
 0.         0.         0.         1.         0.6880871  0.
 1.         0.81149749 1.         1.         0.         0.
 0.         0.95139423 0.26916905 1.         0.08056746 1.
 0.46519522 0.         0.         1.         0.022607   0.59435329]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.30059073
 0.         0.         0.         1.         0.93865225 0.
 1.         0.96508517 1.         1.         0.         0.71201572
 0.         0.39902894 0.         1.         0.         1.
 0.60826554 0.         0.         1.         0.         0.        ]
wv_lg shape (30, 1)
[[0.2562048 ]
 [0.25594281]
 [0.25567177]
 [0.25618993]
 [0.25581969]
 [0.26433709]
 [0.26471673]
 [0.2650316 ]
 [0.2648715 ]
 [0.26313135]
 [0.26476988]
 [0.26611906]
 [0.26393063]
 [0.26429901]
 [0.26391197]
 [0.2624678 ]
 [0.26372529]
 [0.2658459 ]
 [0.26451038]
 [0.26532788]
 [0.26453511]
 [0.26330013]
 [0.26473007]
 [0.26512391]
 [0.26443285]
 [0.26461738]
 [0.2645759 ]
 [0.26440133]
 [0.26468466]
 [0.26362809]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         0.24218301 1.         1.
 0.         1.         0.91428814 1.         1.         0.92585895
 0.3316541  1.         0.08651365 1.         0.74631087 0.
 1.         1.         1.         1.         0.88571754 1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.43481967 0.
 1.         0.68320336 1.         1.         0.         0.
 0.         1.         0.68694083 1.         0.20211401 1.
 0.62964077 0.         0.         0.44536139 0.95903445 1.        ]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.2562048  1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.25594281 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.25567177 1.
  0.         0.         0.        ]
 [0.03250273 0.         0.         0.         0.25618993 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.25581969 1.
  0.         0.         0.        ]
 [0.         0.         0.27961206 0.30059073 0.26433709 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26471673 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2650316  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.2648715  1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.26313135 1.
  0.24218301 1.         1.        ]
 [0.         0.         0.6880871  0.93865225 0.26476988 1.
  1.         0.43481967 1.        ]
 [0.         1.         0.         0.         0.26611906 1.
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.26393063 1.
  0.         1.         1.        ]
 [0.         0.         0.81149749 0.96508517 0.26429901 1.
  1.         0.68320336 1.        ]
 [0.         0.         1.         1.         0.26391197 1.
  0.91428814 1.         1.        ]
 [0.         0.71328923 1.         1.         0.2624678  1.
  1.         1.         1.        ]
 [0.         0.08287956 0.         0.         0.26372529 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.71201572 0.2658459  1.
  0.92585895 0.         1.        ]
 [0.         0.31389061 0.         0.         0.26451038 1.
  0.3316541  0.         1.        ]
 [0.         1.         0.95139423 0.39902894 0.26532788 1.
  1.         1.         1.        ]
 [0.         0.03456697 0.26916905 0.         0.26453511 1.
  0.08651365 0.68694083 1.        ]
 [0.         1.         1.         1.         0.26330013 1.
  1.         1.         1.        ]
 [0.         0.         0.08056746 0.         0.26473007 1.
  0.74631087 0.20211401 1.        ]
 [0.         1.         1.         1.         0.26512391 1.
  0.         1.         1.        ]
 [0.         0.         0.46519522 0.60826554 0.26443285 1.
  1.         0.62964077 1.        ]
 [0.         0.         0.         0.         0.26461738 1.
  1.         0.         1.        ]
 [0.         0.08287956 0.         0.         0.2645759  1.
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.26440133 1.
  1.         0.44536139 1.        ]
 [0.         0.         0.022607   0.         0.26468466 1.
  0.88571754 0.95903445 1.        ]
 [0.         0.         0.59435329 0.         0.26362809 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 19 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1.         0.         0.15952042 0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.37639149 0.         0.
 0.42906307 0.         0.         0.         0.         0.
 0.         0.         0.         1.         0.         0.
 1.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.76627489
 0.27445513 0.         1.         0.14218331 0.95493005 1.
 0.27645783 1.         0.         1.         0.         0.25425114
 1.         0.93210776 0.         1.         0.25869818 1.
 0.         0.09947176 0.         0.         0.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.81990159
 0.93563557 0.         1.         0.55914407 1.         1.
 0.35300262 1.         0.         1.         0.         0.88394227
 1.         1.         0.         1.         0.87245268 1.
 0.         0.55456444 0.         0.         0.06743018 0.        ]
wv_lg shape (30, 1)
[[0.25965377]
 [0.25961985]
 [0.25961963]
 [0.25956282]
 [0.25968685]
 [0.26803255]
 [0.26840024]
 [0.26872946]
 [0.267993  ]
 [0.26646337]
 [0.26919441]
 [0.26878653]
 [0.26932846]
 [0.26861031]
 [0.26913534]
 [0.26746531]
 [0.26930456]
 [0.2685664 ]
 [0.26796544]
 [0.26849318]
 [0.26882271]
 [0.269165  ]
 [0.26992583]
 [0.26779785]
 [0.26986633]
 [0.26837951]
 [0.26908817]
 [0.26907862]
 [0.2680657 ]
 [0.26951774]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.92878204 1.         0.77409978 0.4426258
 0.21361751 0.78922846 1.         0.         0.40330567 1.
 0.79809222 0.69314114 1.         0.         1.         1.
 1.         1.         0.89330555 0.75996023 1.         0.62634038]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.65440933
 0.         0.         1.         0.         0.47947277 0.96122154
 0.         1.         0.         1.         0.         0.02670419
 1.         0.7809489  0.         0.39885979 0.         1.
 0.         0.00887502 0.         0.29582571 0.         0.        ]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.25965377 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.25961985 1.
  0.         0.         0.        ]
 [0.15952042 0.         0.         0.         0.25961963 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.25956282 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.25968685 1.
  0.         0.         0.        ]
 [0.         0.         0.76627489 0.81990159 0.26803255 1.
  0.         0.65440933 1.        ]
 [0.         0.         0.27445513 0.93563557 0.26840024 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26872946 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.267993   1.
  0.92878204 1.         1.        ]
 [0.         0.37639149 0.14218331 0.55914407 0.26646337 1.
  1.         0.         1.        ]
 [0.         0.         0.95493005 1.         0.26919441 1.
  0.77409978 0.47947277 1.        ]
 [0.         0.         1.         1.         0.26878653 1.
  0.4426258  0.96122154 1.        ]
 [0.         0.42906307 0.27645783 0.35300262 0.26932846 1.
  0.21361751 0.         1.        ]
 [0.         0.         1.         1.         0.26861031 1.
  0.78922846 1.         1.        ]
 [0.         0.         0.         0.         0.26913534 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.26746531 1.
  0.         1.         1.        ]
 [0.         0.         0.         0.         0.26930456 1.
  0.40330567 0.         1.        ]
 [0.         0.         0.25425114 0.88394227 0.2685664  1.
  1.         0.02670419 1.        ]
 [0.         0.         1.         1.         0.26796544 1.
  0.79809222 1.         1.        ]
 [0.         0.         0.93210776 1.         0.26849318 1.
  0.69314114 0.7809489  1.        ]
 [0.         0.         0.         0.         0.26882271 1.
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.269165   1.
  0.         0.39885979 1.        ]
 [0.         0.         0.25869818 0.87245268 0.26992583 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.26779785 1.
  1.         1.         1.        ]
 [0.         1.         0.         0.         0.26986633 1.
  1.         0.         1.        ]
 [0.         0.         0.09947176 0.55456444 0.26837951 1.
  1.         0.00887502 1.        ]
 [0.         0.         0.         0.         0.26908817 1.
  0.89330555 0.         1.        ]
 [0.         0.         0.         0.         0.26907862 1.
  0.75996023 0.29582571 1.        ]
 [0.         0.         0.         0.06743018 0.2680657  1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.26951774 1.
  0.62634038 0.         1.        ]]

Best Training Poisoning Accuracy:
1.0
#####################         POISON         ###############################################

############################################################################################

comm_round: 20 | global_test_acc: 60.000% | global_f1: 0.7499999999999999 | global_precision: 0.6
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.60      1.00      0.75         6

    accuracy                           0.60        10
   macro avg       0.30      0.50      0.37        10
weighted avg       0.36      0.60      0.45        10

Accuracy per class:
[[6 0]
 [4 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.63134742 1.         0.25235568
 0.8549292  0.37213698 1.         0.65558961 0.         0.37213698
 0.         0.63134742 0.         0.65558961 0.         0.34973202
 0.         0.94613966 0.         1.         1.         1.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.         0.         0.57665115
 1.         0.30444921 1.         0.46025698 1.         0.
 0.49406653 0.87920993 0.21656927 0.00504814 0.         0.28560166
 0.         1.         1.         1.         0.21154207 0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.30220736 0.         0.42459475 0.90370681
 1.         0.57125244 1.         0.23529405 1.         0.
 1.         0.73231139 0.08716665 0.         0.         0.16249315
 0.         1.         1.         1.         0.46344545 0.        ]
wv_lg shape (30, 1)
[[0.26281789]
 [0.26333101]
 [0.26320202]
 [0.26308237]
 [0.26322514]
 [0.27267857]
 [0.27287562]
 [0.27132687]
 [0.27167425]
 [0.27316684]
 [0.27300281]
 [0.27198784]
 [0.26990987]
 [0.27162535]
 [0.27176242]
 [0.27377366]
 [0.2694639 ]
 [0.27143618]
 [0.27219012]
 [0.27177186]
 [0.27207591]
 [0.27338132]
 [0.27279358]
 [0.27024678]
 [0.27351674]
 [0.27268154]
 [0.27245625]
 [0.27212537]
 [0.27178372]
 [0.27125609]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         1.         1.         0.36541054
 0.         1.         0.28191535 1.         1.         1.
 1.         1.         1.         0.69443838 1.         0.96978722
 1.         0.         0.74186825 0.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.95246898 0.         0.         0.         0.29375847
 1.         0.         0.76005693 0.49575132 1.         0.
 0.         1.         0.19830294 0.19580638 0.         0.53397665
 0.         1.         0.9750235  1.         0.02545161 0.81948731]
xy shape: (30, 9)
[[0.53107207 0.         0.         0.         0.26281789 1.
  0.         0.         0.        ]
 [0.53107207 0.         0.         0.         0.26333101 1.
  0.         0.         0.        ]
 [0.53107207 0.         0.         0.         0.26320202 1.
  0.         0.         0.        ]
 [0.53107207 0.         0.         0.         0.26308237 1.
  0.         0.         0.        ]
 [0.53107207 0.         0.         0.         0.26322514 1.
  0.         0.         0.        ]
 [0.53107207 0.         0.         0.         0.27267857 1.
  1.         0.         1.        ]
 [0.53107207 0.         0.         0.         0.27287562 1.
  1.         0.         1.        ]
 [0.53107207 0.         1.         1.         0.27132687 1.
  1.         0.95246898 1.        ]
 [0.53107207 1.         0.         0.30220736 0.27167425 1.
  1.         0.         1.        ]
 [0.53107207 0.63134742 0.         0.         0.27316684 1.
  1.         0.         1.        ]
 [0.53107207 1.         0.         0.42459475 0.27300281 1.
  1.         0.         1.        ]
 [0.53107207 0.25235568 0.57665115 0.90370681 0.27198784 1.
  0.36541054 0.29375847 1.        ]
 [0.53107207 0.8549292  1.         1.         0.26990987 1.
  0.         1.         1.        ]
 [0.53107207 0.37213698 0.30444921 0.57125244 0.27162535 1.
  1.         0.         1.        ]
 [0.53107207 1.         1.         1.         0.27176242 1.
  0.28191535 0.76005693 1.        ]
 [0.53107207 0.65558961 0.46025698 0.23529405 0.27377366 1.
  1.         0.49575132 1.        ]
 [0.53107207 0.         1.         1.         0.2694639  1.
  1.         1.         1.        ]
 [0.53107207 0.37213698 0.         0.         0.27143618 1.
  1.         0.         1.        ]
 [0.53107207 0.         0.49406653 1.         0.27219012 1.
  1.         0.         1.        ]
 [0.53107207 0.63134742 0.87920993 0.73231139 0.27177186 1.
  1.         1.         1.        ]
 [0.53107207 0.         0.21656927 0.08716665 0.27207591 1.
  1.         0.19830294 1.        ]
 [0.53107207 0.65558961 0.00504814 0.         0.27338132 1.
  0.69443838 0.19580638 1.        ]
 [0.53107207 0.         0.         0.         0.27279358 1.
  1.         0.         1.        ]
 [0.53107207 0.34973202 0.28560166 0.16249315 0.27024678 1.
  0.96978722 0.53397665 1.        ]
 [0.53107207 0.         0.         0.         0.27351674 1.
  1.         0.         1.        ]
 [0.53107207 0.94613966 1.         1.         0.27268154 1.
  0.         1.         1.        ]
 [0.53107207 0.         1.         1.         0.27245625 1.
  0.74186825 0.9750235  1.        ]
 [0.53107207 1.         1.         1.         0.27212537 1.
  0.         1.         1.        ]
 [0.53107207 1.         0.21154207 0.46344545 0.27178372 1.
  1.         0.02545161 1.        ]
 [0.53107207 1.         0.         0.         0.27125609 1.
  1.         0.81948731 1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 21 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.34080259
 0.11604966 0.         0.         1.         0.99687781 0.
 0.         0.         0.         0.         0.34080259 0.84062287
 0.21104678 0.         0.         0.         0.43533075 1.
 0.         0.         1.         0.         0.07592849 0.51540666]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.81626226 0.         0.         1.         1.         0.88858811
 0.         0.52898146 0.         0.         0.45287928 0.
 0.73728447 1.         0.         0.99333346 0.70654669 1.
 1.         1.         1.         0.         0.         0.17149583]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.83745744 0.         0.         1.         1.         1.
 0.         0.32085466 0.         0.         0.         0.
 0.64074942 1.         0.         1.         0.35921407 1.
 0.88842405 1.         1.         0.         0.         0.        ]
wv_lg shape (30, 1)
[[0.26655973]
 [0.26662668]
 [0.26698306]
 [0.2667474 ]
 [0.26685866]
 [0.27674583]
 [0.27692996]
 [0.2760407 ]
 [0.27670162]
 [0.27461813]
 [0.27710145]
 [0.27617224]
 [0.2773147 ]
 [0.27686366]
 [0.27710717]
 [0.27644185]
 [0.27683309]
 [0.27487935]
 [0.27609242]
 [0.27497229]
 [0.27780989]
 [0.27476524]
 [0.27650904]
 [0.27715013]
 [0.27726014]
 [0.27403363]
 [0.27333014]
 [0.27719272]
 [0.27696119]
 [0.27718108]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.12177336
 1.         0.43531861 1.         1.         0.19776474 0.98949108
 1.         1.         1.         1.         1.         0.78187325
 0.06643258 0.4595254  1.         0.67358863 1.         0.46606716
 0.99344595 0.52261923 0.82298992 1.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.97089246 0.         0.         0.93707945 0.37049061 0.18776791
 0.         0.62981152 0.         0.         0.50542334 0.
 0.54714789 0.67813402 0.         0.53847005 0.85241679 1.
 0.94604295 1.         1.         0.         0.         0.8358518 ]
xy shape: (30, 9)
[[1.         0.         0.         0.         0.26655973 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.26662668 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.26698306 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.2667474  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.26685866 1.
  0.         0.         0.        ]
 [0.         0.34080259 1.         1.         0.27674583 1.
  0.12177336 1.         1.        ]
 [0.         0.11604966 0.81626226 0.83745744 0.27692996 1.
  1.         0.97089246 1.        ]
 [0.         0.         0.         0.         0.2760407  1.
  0.43531861 0.         1.        ]
 [0.         0.         0.         0.         0.27670162 1.
  1.         0.         1.        ]
 [0.         1.         1.         1.         0.27461813 1.
  1.         0.93707945 1.        ]
 [0.         0.99687781 1.         1.         0.27710145 1.
  0.19776474 0.37049061 1.        ]
 [0.         0.         0.88858811 1.         0.27617224 1.
  0.98949108 0.18776791 1.        ]
 [0.         0.         0.         0.         0.2773147  1.
  1.         0.         1.        ]
 [0.         0.         0.52898146 0.32085466 0.27686366 1.
  1.         0.62981152 1.        ]
 [0.         0.         0.         0.         0.27710717 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.         0.27644185 1.
  1.         0.         1.        ]
 [0.         0.34080259 0.45287928 0.         0.27683309 1.
  1.         0.50542334 1.        ]
 [0.         0.84062287 0.         0.         0.27487935 1.
  0.78187325 0.         1.        ]
 [0.         0.21104678 0.73728447 0.64074942 0.27609242 1.
  0.06643258 0.54714789 1.        ]
 [0.         0.         1.         1.         0.27497229 1.
  0.4595254  0.67813402 1.        ]
 [0.         0.         0.         0.         0.27780989 1.
  1.         0.         1.        ]
 [0.         0.         0.99333346 1.         0.27476524 1.
  0.67358863 0.53847005 1.        ]
 [0.         0.43533075 0.70654669 0.35921407 0.27650904 1.
  1.         0.85241679 1.        ]
 [0.         1.         1.         1.         0.27715013 1.
  0.46606716 1.         1.        ]
 [0.         0.         1.         0.88842405 0.27726014 1.
  0.99344595 0.94604295 1.        ]
 [0.         0.         1.         1.         0.27403363 1.
  0.52261923 1.         1.        ]
 [0.         1.         1.         1.         0.27333014 1.
  0.82298992 1.         1.        ]
 [0.         0.         0.         0.         0.27719272 1.
  1.         0.         1.        ]
 [0.         0.07592849 0.         0.         0.27696119 1.
  1.         0.         1.        ]
 [0.         0.51540666 0.17149583 0.         0.27718108 1.
  1.         0.8358518  1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 22 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.45698602
 0.         0.         0.         0.         1.         0.35453362
 0.         0.         0.45698602 0.54660864 0.10117801 0.67275291
 1.         0.52032933 1.         0.         0.55351006 0.88261637
 1.         0.         0.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.         0.89980838 0.         0.
 0.         0.         1.         0.37280958 0.8293659  0.44620166
 0.         0.         1.         0.         0.         1.
 1.         0.         1.         1.         0.59570496 0.66784674]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 1.         1.         0.         0.57156592 0.         0.
 0.         0.         0.9457764  0.63289778 1.         0.90498747
 0.         0.         1.         0.         0.53429404 1.
 1.         0.         1.         1.         0.22347729 0.76423839]
wv_lg shape (30, 1)
[[0.27118975]
 [0.27129511]
 [0.27100934]
 [0.27103856]
 [0.27060774]
 [0.28070106]
 [0.27984305]
 [0.28044948]
 [0.28166657]
 [0.27907995]
 [0.27846013]
 [0.27922331]
 [0.28121199]
 [0.28029121]
 [0.28049906]
 [0.27899889]
 [0.28129907]
 [0.27986905]
 [0.27932818]
 [0.28201948]
 [0.27835746]
 [0.28162513]
 [0.28198431]
 [0.28116134]
 [0.28016786]
 [0.28125932]
 [0.28037235]
 [0.2792165 ]
 [0.27941969]
 [0.28000985]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.77328125 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.80612777 1.         1.         1.         1.
 1.         0.96144312 1.         1.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.
 0.54185671 1.         0.         1.         0.         0.
 0.         0.         1.         0.03642607 0.10554721 0.
 0.         0.         1.         0.         0.         1.
 1.         0.         1.         0.51116523 0.9022912  0.14034326]
xy shape: (30, 9)
[[0.54197755 0.         0.         0.         0.27118975 1.
  0.         0.         0.        ]
 [0.54197755 0.         0.         0.         0.27129511 1.
  0.         0.         0.        ]
 [0.54197755 0.         0.         0.         0.27100934 1.
  0.         0.         0.        ]
 [0.54197755 0.         0.         0.         0.27103856 1.
  0.         0.         0.        ]
 [0.54197755 0.         0.         0.         0.27060774 1.
  0.         0.         0.        ]
 [0.54197755 0.45698602 0.         0.         0.28070106 1.
  1.         0.         1.        ]
 [0.54197755 0.         1.         1.         0.27984305 1.
  0.77328125 0.54185671 1.        ]
 [0.54197755 0.         1.         1.         0.28044948 1.
  1.         1.         1.        ]
 [0.54197755 0.         0.         0.         0.28166657 1.
  1.         0.         1.        ]
 [0.54197755 0.         0.89980838 0.57156592 0.27907995 1.
  1.         1.         1.        ]
 [0.54197755 1.         0.         0.         0.27846013 1.
  1.         0.         1.        ]
 [0.54197755 0.35453362 0.         0.         0.27922331 1.
  1.         0.         1.        ]
 [0.54197755 0.         0.         0.         0.28121199 1.
  1.         0.         1.        ]
 [0.54197755 0.         0.         0.         0.28029121 1.
  1.         0.         1.        ]
 [0.54197755 0.45698602 1.         0.9457764  0.28049906 1.
  1.         1.         1.        ]
 [0.54197755 0.54660864 0.37280958 0.63289778 0.27899889 1.
  1.         0.03642607 1.        ]
 [0.54197755 0.10117801 0.8293659  1.         0.28129907 1.
  1.         0.10554721 1.        ]
 [0.54197755 0.67275291 0.44620166 0.90498747 0.27986905 1.
  1.         0.         1.        ]
 [0.54197755 1.         0.         0.         0.27932818 1.
  1.         0.         1.        ]
 [0.54197755 0.52032933 0.         0.         0.28201948 1.
  0.80612777 0.         1.        ]
 [0.54197755 1.         1.         1.         0.27835746 1.
  1.         1.         1.        ]
 [0.54197755 0.         0.         0.         0.28162513 1.
  1.         0.         1.        ]
 [0.54197755 0.55351006 0.         0.53429404 0.28198431 1.
  1.         0.         1.        ]
 [0.54197755 0.88261637 1.         1.         0.28116134 1.
  1.         1.         1.        ]
 [0.54197755 1.         1.         1.         0.28016786 1.
  1.         1.         1.        ]
 [0.54197755 0.         0.         0.         0.28125932 1.
  0.96144312 0.         1.        ]
 [0.54197755 0.         1.         1.         0.28037235 1.
  1.         1.         1.        ]
 [0.54197755 0.         1.         1.         0.2792165  1.
  1.         0.51116523 1.        ]
 [0.54197755 0.         0.59570496 0.22347729 0.27941969 1.
  1.         0.9022912  1.        ]
 [0.54197755 0.         0.66784674 0.76423839 0.28000985 1.
  1.         0.14034326 1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 23 | global_test_acc: 70.000% | global_f1: 0.8235294117647058 | global_precision: 0.7
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.70      1.00      0.82         7

    accuracy                           0.70        10
   macro avg       0.35      0.50      0.41        10
weighted avg       0.49      0.70      0.58        10

Accuracy per class:
[[7 0]
 [3 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.45105674
 1.         0.         0.63398235 1.         0.         0.
 0.20279212 1.         0.         0.59635071 0.         0.63398235
 1.         1.         0.54426136 0.         0.         0.54426136
 0.         0.20279212 0.         0.         0.58423936 0.59635071]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.12668518
 0.98509796 0.         0.47400699 0.         0.24103922 0.64606306
 0.52955482 0.         0.16249816 0.         0.94264642 0.80744488
 0.         1.         1.         0.41556463 1.         0.
 0.         0.         0.13984186 1.         1.         0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.47220241 0.         0.         0.         0.3849528  0.86090641
 0.24655487 0.         0.         0.1034451  0.02205449 0.
 0.         1.         1.         0.61094792 0.45598246 0.
 0.         0.         0.46110786 1.         0.57433636 0.        ]
wv_lg shape (30, 1)
[[0.27529832]
 [0.27557812]
 [0.27587566]
 [0.27532228]
 [0.27601612]
 [0.28384578]
 [0.28418397]
 [0.28525119]
 [0.28349976]
 [0.28482642]
 [0.28442553]
 [0.28391554]
 [0.28446939]
 [0.28367513]
 [0.28447617]
 [0.28416841]
 [0.28486773]
 [0.2842783 ]
 [0.28634724]
 [0.2825207 ]
 [0.28480093]
 [0.28427582]
 [0.2846272 ]
 [0.28563967]
 [0.28536129]
 [0.28529564]
 [0.28510344]
 [0.28420469]
 [0.28416769]
 [0.28495365]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.61353785 1.         1.         1.         1.
 0.83957463 1.         0.70846973 1.         0.48254181 0.95459892
 0.01669957 0.35705944 1.         1.         1.         1.
 1.         1.         1.         1.         0.38160438 0.77822125]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.61464968
 1.         0.         1.         0.         0.         0.33201441
 0.75664708 0.         0.47395584 0.         1.         1.
 0.17664422 1.         1.         0.32883552 1.         0.07275572
 0.         0.         0.         1.         1.         0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.27529832 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.27557812 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.27587566 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.27532228 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.27601612 1.
  0.         0.         0.        ]
 [0.         0.45105674 0.12668518 0.         0.28384578 1.
  1.         0.61464968 1.        ]
 [0.         1.         0.98509796 0.47220241 0.28418397 1.
  1.         1.         1.        ]
 [0.         0.         0.         0.         0.28525119 1.
  0.61353785 0.         1.        ]
 [0.         0.63398235 0.47400699 0.         0.28349976 1.
  1.         1.         1.        ]
 [0.         1.         0.         0.         0.28482642 1.
  1.         0.         1.        ]
 [0.         0.         0.24103922 0.3849528  0.28442553 1.
  1.         0.         1.        ]
 [0.         0.         0.64606306 0.86090641 0.28391554 1.
  1.         0.33201441 1.        ]
 [0.         0.20279212 0.52955482 0.24655487 0.28446939 1.
  0.83957463 0.75664708 1.        ]
 [0.         1.         0.         0.         0.28367513 1.
  1.         0.         1.        ]
 [0.         0.         0.16249816 0.         0.28447617 1.
  0.70846973 0.47395584 1.        ]
 [0.         0.59635071 0.         0.1034451  0.28416841 1.
  1.         0.         1.        ]
 [0.         0.         0.94264642 0.02205449 0.28486773 1.
  0.48254181 1.         1.        ]
 [0.         0.63398235 0.80744488 0.         0.2842783  1.
  0.95459892 1.         1.        ]
 [0.         1.         0.         0.         0.28634724 1.
  0.01669957 0.17664422 1.        ]
 [0.         1.         1.         1.         0.2825207  1.
  0.35705944 1.         1.        ]
 [1.         0.54426136 1.         1.         0.28480093 1.
  1.         1.         1.        ]
 [0.         0.         0.41556463 0.61094792 0.28427582 1.
  1.         0.32883552 1.        ]
 [0.         0.         1.         0.45598246 0.2846272  1.
  1.         1.         1.        ]
 [0.         0.54426136 0.         0.         0.28563967 1.
  1.         0.07275572 1.        ]
 [0.         0.         0.         0.         0.28536129 1.
  1.         0.         1.        ]
 [0.         0.20279212 0.         0.         0.28529564 1.
  1.         0.         1.        ]
 [0.         0.         0.13984186 0.46110786 0.28510344 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.28420469 1.
  1.         1.         1.        ]
 [0.         0.58423936 1.         0.57433636 0.28416769 1.
  0.38160438 1.         1.        ]
 [0.         0.59635071 0.         0.         0.28495365 1.
  0.77822125 0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 24 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         1.         0.         0.         0.
 0.         0.38912764 0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.74601701
 0.52565277 0.         0.52565277 1.         0.         0.
 0.         0.         0.19312042 1.         0.         1.
 0.         0.32048764 0.95597528 0.86247044 0.36657299 1.
 0.         0.         1.         0.8594926  0.40130847 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         1.         0.70797567
 0.         1.         1.         0.         1.         0.
 1.         1.         0.         0.         0.         1.
 0.         0.7183859  1.         1.         0.53207825 0.87135882]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         1.         1.         0.80851066
 0.         1.         1.         0.         1.         0.
 1.         1.         0.         0.         0.         0.97908422
 0.09038658 1.         1.         1.         0.19522493 1.        ]
wv_lg shape (30, 1)
[[0.27983355]
 [0.2798218 ]
 [0.27929679]
 [0.27990242]
 [0.28017731]
 [0.28779087]
 [0.28891709]
 [0.28792943]
 [0.28608764]
 [0.28820793]
 [0.28836221]
 [0.28890618]
 [0.28978685]
 [0.28871803]
 [0.28726176]
 [0.28959865]
 [0.28849794]
 [0.28945456]
 [0.28814122]
 [0.28797289]
 [0.2899614 ]
 [0.28816554]
 [0.28995449]
 [0.2886815 ]
 [0.2888598 ]
 [0.28855509]
 [0.2900746 ]
 [0.28636201]
 [0.28825372]
 [0.28875528]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         0.17467146
 1.         0.95077918 1.         1.         0.12554782 1.
 1.         1.         0.         1.         0.         1.
 0.23344827 0.4865681  1.         1.         1.         0.27645774
 0.8083759  0.98726358 1.         1.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         1.         1.         0.50484034 1.         0.43400803
 0.         1.         1.         0.         1.         0.
 1.         1.         0.         0.         0.         1.
 0.01984151 0.29394764 0.81397101 1.         0.80969363 0.43253571]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.27983355 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.2798218  1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.27929679 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.27990242 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.28017731 1.
  0.         0.         0.        ]
 [0.         0.74601701 1.         1.         0.28779087 1.
  0.17467146 1.         1.        ]
 [0.         0.52565277 0.         0.         0.28891709 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.28792943 1.
  0.95077918 1.         1.        ]
 [0.         0.52565277 1.         1.         0.28608764 1.
  1.         1.         1.        ]
 [0.         1.         1.         1.         0.28820793 1.
  1.         0.50484034 1.        ]
 [0.         0.         1.         1.         0.28836221 1.
  0.12554782 1.         1.        ]
 [0.         0.         0.70797567 0.80851066 0.28890618 1.
  1.         0.43400803 1.        ]
 [0.         0.         0.         0.         0.28978685 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.28871803 1.
  1.         1.         1.        ]
 [1.         0.19312042 1.         1.         0.28726176 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.28959865 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.28849794 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.28945456 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.28814122 1.
  0.23344827 1.         1.        ]
 [0.38912764 0.32048764 1.         1.         0.28797289 1.
  0.4865681  1.         1.        ]
 [0.         0.95597528 0.         0.         0.2899614  1.
  1.         0.         1.        ]
 [0.         0.86247044 0.         0.         0.28816554 1.
  1.         0.         1.        ]
 [0.         0.36657299 0.         0.         0.28995449 1.
  1.         0.         1.        ]
 [0.         1.         1.         0.97908422 0.2886815  1.
  0.27645774 1.         1.        ]
 [0.         0.         0.         0.09038658 0.2888598  1.
  0.8083759  0.01984151 1.        ]
 [0.         0.         0.7183859  1.         0.28855509 1.
  0.98726358 0.29394764 1.        ]
 [0.         1.         1.         1.         0.2900746  1.
  1.         0.81397101 1.        ]
 [0.         0.8594926  1.         1.         0.28636201 1.
  1.         1.         1.        ]
 [0.         0.40130847 0.53207825 0.19522493 0.28825372 1.
  1.         0.80969363 1.        ]
 [0.         0.         0.87135882 1.         0.28875528 1.
  1.         0.43253571 1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 25 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.         0.         0.         0.         0.70254499 0.05672855
 0.77832904 0.         0.12723721 0.         1.         0.
 0.         0.         0.         0.46616685 0.12723721 1.
 0.77832904 0.79461777 0.         0.85098348 1.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.35045213
 0.         0.36822924 0.3752222  0.67515413 0.58821493 1.
 0.         1.         0.96239634 0.8037484  0.06309873 0.
 1.         1.         1.         1.         1.         0.57180298
 1.         1.         0.83586143 0.78078593 1.         0.73317244]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.03139222 0.22800349 0.17765236 0.58830817 1.
 0.         1.         0.65277053 0.95132207 0.27992606 0.
 0.9037441  0.94459951 1.         1.         1.         0.86023495
 1.         1.         0.81620426 0.42763618 0.95723177 0.72910691]
wv_lg shape (30, 1)
[[0.28245082]
 [0.28222675]
 [0.28280503]
 [0.28280659]
 [0.28295446]
 [0.29311097]
 [0.29327355]
 [0.29267855]
 [0.29328272]
 [0.29212326]
 [0.29226668]
 [0.29136589]
 [0.29302846]
 [0.29263761]
 [0.29357767]
 [0.29258908]
 [0.29126255]
 [0.29354602]
 [0.29310443]
 [0.29203378]
 [0.28986482]
 [0.29168352]
 [0.29330514]
 [0.2939581 ]
 [0.28992433]
 [0.29380406]
 [0.29159966]
 [0.29116266]
 [0.29118225]
 [0.29351933]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         0.9603909  1.         0.         1.         0.
 1.         0.6980481  1.         1.         0.47448372 1.
 0.75338919 0.86428069 0.45890792 0.35780718 1.         0.58425977
 1.         0.89212897 0.81506078 0.61288169 0.8849609  0.87997179]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.36601645
 0.         0.         0.         0.30964197 0.         0.80669552
 0.         0.136527   0.53767596 0.         0.         0.
 0.79119741 0.80585916 0.78074411 1.         0.97261905 0.
 0.40010016 0.97163708 0.1118084  0.33220328 0.61682889 0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.28245082 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.28222675 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.28280503 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.28280659 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.28295446 1.
  0.         0.         0.        ]
 [0.         1.         0.35045213 0.         0.29311097 1.
  1.         0.36601645 1.        ]
 [0.         0.         0.         0.         0.29327355 1.
  1.         0.         1.        ]
 [0.         0.         0.36822924 0.03139222 0.29267855 1.
  0.9603909  0.         1.        ]
 [0.         0.         0.3752222  0.22800349 0.29328272 1.
  1.         0.         1.        ]
 [0.         0.         0.67515413 0.17765236 0.29212326 1.
  0.         0.30964197 1.        ]
 [0.         0.70254499 0.58821493 0.58830817 0.29226668 1.
  1.         0.         1.        ]
 [0.         0.05672855 1.         1.         0.29136589 1.
  0.         0.80669552 1.        ]
 [0.         0.77832904 0.         0.         0.29302846 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.29263761 1.
  0.6980481  0.136527   1.        ]
 [0.         0.12723721 0.96239634 0.65277053 0.29357767 1.
  1.         0.53767596 1.        ]
 [0.         0.         0.8037484  0.95132207 0.29258908 1.
  1.         0.         1.        ]
 [0.         1.         0.06309873 0.27992606 0.29126255 1.
  0.47448372 0.         1.        ]
 [0.         0.         0.         0.         0.29354602 1.
  1.         0.         1.        ]
 [0.         0.         1.         0.9037441  0.29310443 1.
  0.75338919 0.79119741 1.        ]
 [0.         0.         1.         0.94459951 0.29203378 1.
  0.86428069 0.80585916 1.        ]
 [0.         0.         1.         1.         0.28986482 1.
  0.45890792 0.78074411 1.        ]
 [1.         0.46616685 1.         1.         0.29168352 1.
  0.35780718 1.         1.        ]
 [0.         0.12723721 1.         1.         0.29330514 1.
  1.         0.97261905 1.        ]
 [0.         1.         0.57180298 0.86023495 0.2939581  1.
  0.58425977 0.         1.        ]
 [0.         0.77832904 1.         1.         0.28992433 1.
  1.         0.40010016 1.        ]
 [0.         0.79461777 1.         1.         0.29380406 1.
  0.89212897 0.97163708 1.        ]
 [0.         0.         0.83586143 0.81620426 0.29159966 1.
  0.81506078 0.1118084  1.        ]
 [0.         0.85098348 0.78078593 0.42763618 0.29116266 1.
  0.61288169 0.33220328 1.        ]
 [0.         1.         1.         0.95723177 0.29118225 1.
  0.8849609  0.61682889 1.        ]
 [0.         0.         0.73317244 0.72910691 0.29351933 1.
  0.87997179 0.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 26 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         1.         0.         0.14163638 1.         0.
 0.56900432 1.         1.         1.         0.06127156 1.
 0.         0.56900432 0.06127156 1.         0.42551118 1.
 0.         1.         1.         0.         0.         0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.02614454
 0.         0.         0.61398419 1.         0.         0.
 1.         1.         1.         0.         0.25307675 0.52638594
 1.         0.75186612 0.         0.25458772 1.         0.49174592
 1.         0.58532547 0.68689284 0.         0.69865689 0.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.31872886
 0.         0.         1.         1.         0.         0.09177419
 1.         1.         1.         0.         0.61762405 0.48383358
 1.         0.26081152 0.         0.07324738 1.         0.
 1.         0.86267114 1.         0.37026964 1.         0.        ]
wv_lg shape (30, 1)
[[0.28773   ]
 [0.2880125 ]
 [0.28777064]
 [0.28784405]
 [0.28752637]
 [0.29628826]
 [0.29789726]
 [0.29759858]
 [0.29545697]
 [0.29719257]
 [0.29617743]
 [0.29706963]
 [0.29574995]
 [0.29615625]
 [0.29657276]
 [0.29548358]
 [0.29656597]
 [0.29626258]
 [0.29477347]
 [0.29571296]
 [0.29669561]
 [0.29775961]
 [0.29659433]
 [0.29794255]
 [0.29685961]
 [0.29737826]
 [0.29632559]
 [0.29737445]
 [0.29745299]
 [0.29554728]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         0.41884508 1.         0.8209407
 0.11853949 0.81789425 1.         1.         0.82644885 1.
 0.45201693 0.61313964 0.74871331 0.         1.         1.
 1.         0.         0.41523728 1.         0.73791971 0.4047997 ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.24032329
 0.         0.         0.43241364 1.         0.         0.04023954
 1.         1.         0.80191092 0.         0.         0.86049817
 1.         1.         0.         0.41847167 1.         0.87567802
 1.         0.41090794 0.43524441 0.         0.243109   0.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.28773    1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.2880125  1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.28777064 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.28784405 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.28752637 1.
  0.         0.         0.        ]
 [0.         0.         0.02614454 0.31872886 0.29628826 1.
  1.         0.24032329 1.        ]
 [0.         0.         0.         0.         0.29789726 1.
  1.         0.         1.        ]
 [0.         1.         0.         0.         0.29759858 1.
  1.         0.         1.        ]
 [0.         0.         0.61398419 1.         0.29545697 1.
  1.         0.43241364 1.        ]
 [0.         0.14163638 1.         1.         0.29719257 1.
  0.41884508 1.         1.        ]
 [0.         1.         0.         0.         0.29617743 1.
  1.         0.         1.        ]
 [0.         0.         0.         0.09177419 0.29706963 1.
  0.8209407  0.04023954 1.        ]
 [0.         0.56900432 1.         1.         0.29574995 1.
  0.11853949 1.         1.        ]
 [0.         1.         1.         1.         0.29615625 1.
  0.81789425 1.         1.        ]
 [0.         1.         1.         1.         0.29657276 1.
  1.         0.80191092 1.        ]
 [0.         1.         0.         0.         0.29548358 1.
  1.         0.         1.        ]
 [0.         0.06127156 0.25307675 0.61762405 0.29656597 1.
  0.82644885 0.         1.        ]
 [0.         1.         0.52638594 0.48383358 0.29626258 1.
  1.         0.86049817 1.        ]
 [0.         0.         1.         1.         0.29477347 1.
  0.45201693 1.         1.        ]
 [0.         0.56900432 0.75186612 0.26081152 0.29571296 1.
  0.61313964 1.         1.        ]
 [0.         0.06127156 0.         0.         0.29669561 1.
  0.74871331 0.         1.        ]
 [0.         1.         0.25458772 0.07324738 0.29775961 1.
  0.         0.41847167 1.        ]
 [0.         0.42551118 1.         1.         0.29659433 1.
  1.         1.         1.        ]
 [0.         1.         0.49174592 0.         0.29794255 1.
  1.         0.87567802 1.        ]
 [0.         0.         1.         1.         0.29685961 1.
  1.         1.         1.        ]
 [0.         1.         0.58532547 0.86267114 0.29737826 1.
  0.         0.41090794 1.        ]
 [0.         1.         0.68689284 1.         0.29632559 1.
  0.41523728 0.43524441 1.        ]
 [0.         0.         0.         0.37026964 0.29737445 1.
  1.         0.         1.        ]
 [0.         0.         0.69865689 1.         0.29745299 1.
  0.73791971 0.243109   1.        ]
 [0.         0.         0.         0.         0.29554728 1.
  0.4047997  0.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 27 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         1.
 0.07827325 1.         1.         0.         1.         0.38306652
 0.87141777 0.         0.83317283 0.         0.         0.
 1.         1.         0.         0.15431319 1.         0.
 0.07827325 0.         0.         1.         0.         0.15431319]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.79773553 1.         1.         1.
 0.06386521 1.         1.         0.         0.65642859 1.
 1.         0.         0.47235217 1.         1.         1.
 1.         1.         0.         0.31990648 0.48886344 1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.40806177 1.         1.         0.9217394
 0.         1.         1.         0.         0.2561655  1.
 1.         0.         0.51505121 1.         1.         1.
 0.8227644  1.         0.         0.         0.         1.        ]
wv_lg shape (30, 1)
[[0.29316599]
 [0.29349253]
 [0.29336179]
 [0.29320865]
 [0.29324376]
 [0.29871063]
 [0.2991246 ]
 [0.3014965 ]
 [0.29917303]
 [0.29966489]
 [0.30113651]
 [0.30013835]
 [0.30018119]
 [0.29937997]
 [0.3005737 ]
 [0.30102453]
 [0.30102364]
 [0.29972478]
 [0.30004798]
 [0.30139454]
 [0.30011588]
 [0.30100349]
 [0.3009682 ]
 [0.30017451]
 [0.29971161]
 [0.29935591]
 [0.30041492]
 [0.30022653]
 [0.30150078]
 [0.30071128]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.97934673 0.36883284 1.         0.62903694 0.71996612 0.
 1.         0.40961384 0.751975   1.         1.         0.65657223
 0.         0.04916262 1.         0.28214897 1.         0.67179234
 0.15475204 0.18395972 1.         1.         0.96705841 0.33106941]
wv_std shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         0.53609176 1.         0.3721927  0.81675697
 0.         1.         0.44739125 0.         0.66599691 1.
 1.         0.         0.11480762 1.         1.         1.
 1.         1.         0.         0.63374121 0.47627831 1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.29316599 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.29349253 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.29336179 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.29320865 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.29324376 1.
  0.         0.         0.        ]
 [0.         1.         1.         1.         0.29871063 1.
  1.         1.         1.        ]
 [0.         0.07827325 1.         1.         0.2991246  1.
  0.97934673 1.         1.        ]
 [0.         1.         1.         1.         0.3014965  1.
  0.36883284 1.         1.        ]
 [0.         1.         0.79773553 0.40806177 0.29917303 1.
  1.         0.53609176 1.        ]
 [1.         0.         1.         1.         0.29966489 1.
  0.62903694 1.         1.        ]
 [0.         1.         1.         1.         0.30113651 1.
  0.71996612 0.3721927  1.        ]
 [0.         0.38306652 1.         0.9217394  0.30013835 1.
  0.         0.81675697 1.        ]
 [0.         0.87141777 0.06386521 0.         0.30018119 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.29937997 1.
  0.40961384 1.         1.        ]
 [0.         0.83317283 1.         1.         0.3005737  1.
  0.751975   0.44739125 1.        ]
 [0.         0.         0.         0.         0.30102453 1.
  1.         0.         1.        ]
 [0.         0.         0.65642859 0.2561655  0.30102364 1.
  1.         0.66599691 1.        ]
 [0.         0.         1.         1.         0.29972478 1.
  0.65657223 1.         1.        ]
 [0.         1.         1.         1.         0.30004798 1.
  0.         1.         1.        ]
 [0.         1.         0.         0.         0.30139454 1.
  0.04916262 0.         1.        ]
 [0.         0.         0.47235217 0.51505121 0.30011588 1.
  1.         0.11480762 1.        ]
 [0.         0.15431319 1.         1.         0.30100349 1.
  0.28214897 1.         1.        ]
 [0.         1.         1.         1.         0.3009682  1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.30017451 1.
  0.67179234 1.         1.        ]
 [0.         0.07827325 1.         0.8227644  0.29971161 1.
  0.15475204 1.         1.        ]
 [0.         0.         1.         1.         0.29935591 1.
  0.18395972 1.         1.        ]
 [0.         0.         0.         0.         0.30041492 1.
  1.         0.         1.        ]
 [0.         1.         0.31990648 0.         0.30022653 1.
  1.         0.63374121 1.        ]
 [0.         0.         0.48886344 0.         0.30150078 1.
  0.96705841 0.47627831 1.        ]
 [1.         0.15431319 1.         1.         0.30071128 1.
  0.33106941 1.         1.        ]]

Best Training Poisoning Accuracy:
0.8571428656578064
#####################         POISON         ###############################################

############################################################################################

comm_round: 28 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.35032048 1.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.        ]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.06109009 0.80495612 0.         0.28417777 0.         0.21762338
 0.         0.         0.         0.         1.         0.
 0.66328601 1.         0.         0.         0.         0.56375237
 0.         0.3084396  0.         0.09062069 0.21762338 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.51351596
 1.         1.         0.         0.54533087 1.         1.
 0.31803134 1.         1.         1.         1.         1.
 0.65150311 0.61798336 1.         0.56628837 0.97107736 0.51605513
 0.         1.         0.71002899 0.10523671 1.         0.65902399]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.91372646
 1.         1.         0.         1.         1.         1.
 0.90575851 1.         1.         1.         1.         0.74023649
 1.         0.94649421 1.         0.82200642 1.         0.68420707
 0.         1.         1.         0.23974563 1.         1.        ]
wv_lg shape (30, 1)
[[0.29446141]
 [0.29511427]
 [0.29503627]
 [0.29508171]
 [0.29480852]
 [0.30433398]
 [0.30062474]
 [0.30120152]
 [0.30395041]
 [0.30452747]
 [0.30381295]
 [0.30366626]
 [0.30379018]
 [0.30426945]
 [0.30101246]
 [0.3019188 ]
 [0.30555071]
 [0.30321595]
 [0.30200112]
 [0.30327672]
 [0.30320817]
 [0.30464935]
 [0.30251911]
 [0.30364977]
 [0.30490448]
 [0.3053573 ]
 [0.3031397 ]
 [0.30383239]
 [0.30454126]
 [0.30256162]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.         0.         0.         0.         0.         1.
 0.34103751 0.1967485  1.         0.89757093 0.70618359 0.55647593
 1.         1.         0.88958491 0.98353035 1.         0.92629728
 1.         0.         1.         1.         0.88941867 1.
 1.         0.85573659 1.         1.         1.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.20121285
 0.97735764 0.95646649 0.         0.         1.         1.
 0.         0.21110282 1.         1.         1.         1.
 0.50442916 0.14864187 1.         0.29814114 0.71877083 0.33678353
 0.         0.         0.         0.03834074 1.         0.02385691]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.29446141 1.
  0.         0.         0.        ]
 [0.35032048 0.         0.         0.         0.29511427 1.
  0.         0.         0.        ]
 [1.         0.         0.         0.         0.29503627 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.29508171 1.
  0.         0.         0.        ]
 [0.         0.         0.         0.         0.29480852 1.
  0.         0.         0.        ]
 [0.         0.         0.51351596 0.91372646 0.30433398 1.
  1.         0.20121285 1.        ]
 [0.         0.06109009 1.         1.         0.30062474 1.
  0.34103751 0.97735764 1.        ]
 [0.         0.80495612 1.         1.         0.30120152 1.
  0.1967485  0.95646649 1.        ]
 [0.         0.         0.         0.         0.30395041 1.
  1.         0.         1.        ]
 [0.         0.28417777 0.54533087 1.         0.30452747 1.
  0.89757093 0.         1.        ]
 [0.         0.         1.         1.         0.30381295 1.
  0.70618359 1.         1.        ]
 [0.         0.21762338 1.         1.         0.30366626 1.
  0.55647593 1.         1.        ]
 [0.         0.         0.31803134 0.90575851 0.30379018 1.
  1.         0.         1.        ]
 [0.         0.         1.         1.         0.30426945 1.
  1.         0.21110282 1.        ]
 [0.         0.         1.         1.         0.30101246 1.
  0.88958491 1.         1.        ]
 [0.         0.         1.         1.         0.3019188  1.
  0.98353035 1.         1.        ]
 [0.         1.         1.         1.         0.30555071 1.
  1.         1.         1.        ]
 [0.         0.         1.         0.74023649 0.30321595 1.
  0.92629728 1.         1.        ]
 [0.         0.66328601 0.65150311 1.         0.30200112 1.
  1.         0.50442916 1.        ]
 [0.         1.         0.61798336 0.94649421 0.30327672 1.
  0.         0.14864187 1.        ]
 [0.         0.         1.         1.         0.30320817 1.
  1.         1.         1.        ]
 [0.         0.         0.56628837 0.82200642 0.30464935 1.
  1.         0.29814114 1.        ]
 [0.         0.         0.97107736 1.         0.30251911 1.
  0.88941867 0.71877083 1.        ]
 [0.         0.56375237 0.51605513 0.68420707 0.30364977 1.
  1.         0.33678353 1.        ]
 [0.         0.         0.         0.         0.30490448 1.
  1.         0.         1.        ]
 [0.         0.3084396  1.         1.         0.3053573  1.
  0.85573659 0.         1.        ]
 [0.         0.         0.71002899 1.         0.3031397  1.
  1.         0.         1.        ]
 [0.         0.09062069 0.10523671 0.23974563 0.30383239 1.
  1.         0.03834074 1.        ]
 [0.         0.21762338 1.         1.         0.30454126 1.
  1.         1.         1.        ]
 [0.         0.         0.65902399 1.         0.30256162 1.
  1.         0.02385691 1.        ]]

Best Training Poisoning Accuracy:
0.7857142686843872
#####################         POISON         ###############################################

############################################################################################

comm_round: 29 | global_test_acc: 90.000% | global_f1: 0.9473684210526316 | global_precision: 0.9
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         1
           1       0.90      1.00      0.95         9

    accuracy                           0.90        10
   macro avg       0.45      0.50      0.47        10
weighted avg       0.81      0.90      0.85        10

Accuracy per class:
[[9 0]
 [1 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clientsAfter Nodes removed: Rows 30 cols 21
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0.]
wv_fg shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.6403959  1.         0.98871593 1.         0.
 0.         0.         0.         0.87233139 0.         0.98871593
 0.87233139 0.         0.         0.83418467 0.         0.2363751
 0.83418467 0.         0.         0.         0.94359057 0.        ]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.74338141
 1.         0.41251346 1.         0.         0.19813725 1.
 1.         1.         1.         1.         1.         0.
 0.50765601 1.         1.         1.         0.6800975  1.
 1.         0.24708626 1.         1.         0.68599947 0.83642482]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         1.
 1.         1.         1.         0.         0.09822437 1.
 1.         1.         1.         1.         1.         0.
 1.         1.         1.         1.         1.         1.
 1.         0.91898958 1.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.22488361]
 [0.22497878]
 [0.22482902]
 [0.22502559]
 [0.22495562]
 [0.22825268]
 [0.22804109]
 [0.2281879 ]
 [0.22722038]
 [0.22930398]
 [0.22869486]
 [0.22758257]
 [0.22777766]
 [0.22753382]
 [0.22820887]
 [0.22772864]
 [0.22808515]
 [0.22883813]
 [0.2277568 ]
 [0.2276906 ]
 [0.22769648]
 [0.22742386]
 [0.22814999]
 [0.22740997]
 [0.22765615]
 [0.22827737]
 [0.22734403]
 [0.22748969]
 [0.22836794]
 [0.22824761]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[1.         1.         1.         1.         1.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.69366996 0.         0.13522591
 0.22176244 0.         0.         0.         0.41867215 0.        ]
wv_std shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.22488361 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.22497878 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.22482902 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.22502559 1.
  1.         1.         0.        ]
 [0.         0.         0.         0.         0.22495562 1.
  1.         1.         0.        ]
 [1.         0.         0.74338141 1.         0.22825268 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22804109 1.
  0.         1.         1.        ]
 [1.         0.6403959  0.41251346 1.         0.2281879  1.
  0.         1.         1.        ]
 [0.         1.         1.         1.         0.22722038 1.
  0.         1.         1.        ]
 [0.         0.98871593 0.         0.         0.22930398 1.
  0.         0.         1.        ]
 [0.         1.         0.19813725 0.09822437 0.22869486 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22758257 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22777766 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22753382 1.
  0.         1.         1.        ]
 [1.         0.         1.         1.         0.22820887 1.
  0.         1.         1.        ]
 [0.         0.87233139 1.         1.         0.22772864 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22808515 1.
  0.         1.         1.        ]
 [0.         0.98871593 0.         0.         0.22883813 1.
  0.         1.         1.        ]
 [0.         0.87233139 0.50765601 1.         0.2277568  1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.2276906  1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22769648 1.
  0.         1.         1.        ]
 [0.         0.83418467 1.         1.         0.22742386 1.
  0.69366996 1.         1.        ]
 [0.         0.         0.6800975  1.         0.22814999 1.
  0.         1.         1.        ]
 [0.         0.2363751  1.         1.         0.22740997 1.
  0.13522591 1.         1.        ]
 [0.         0.83418467 1.         1.         0.22765615 1.
  0.22176244 1.         1.        ]
 [1.         0.         0.24708626 0.91898958 0.22827737 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22734403 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.22748969 1.
  0.         1.         1.        ]
 [1.         0.94359057 0.68599947 1.         0.22836794 1.
  0.41867215 1.         1.        ]
 [0.         0.         0.83642482 1.         0.22824761 1.
  0.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.9285714030265808
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 80.000% | global_f1: 0.888888888888889 | global_precision: 0.8
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.80      1.00      0.89         8

    accuracy                           0.80        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.64      0.80      0.71        10

Accuracy per class:
[[8 0]
 [2 0]]
[1. 0.]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients
y shape (30,)
[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
wv_asf shape (30,)
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         1.         0.         1.         0.
 0.         0.         0.         0.         0.         0.
 1.         0.         0.         0.         0.0897935  0.41284321]
wv_fg shape (30,)
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0.]
wv_mn shape (30,)
[0.         0.         0.         0.         0.         0.5624967
 0.         1.         1.         1.         0.63856481 0.64614247
 1.         1.         1.         1.         1.         0.70976709
 1.         0.44210024 1.         1.         1.         1.
 1.         0.         1.         0.55872757 1.         1.        ]
wv_ed shape (30,)
[0.         0.         0.         0.         0.         0.81852996
 0.50679675 1.         1.         1.         0.91687508 1.
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.         1.         1.         1.         1.        ]
wv_lg shape (30, 1)
[[0.16900213]
 [0.16900828]
 [0.1690347 ]
 [0.16901142]
 [0.16900423]
 [0.1703377 ]
 [0.17035423]
 [0.17012207]
 [0.17038202]
 [0.16993681]
 [0.17024851]
 [0.1693318 ]
 [0.17009064]
 [0.17044566]
 [0.16979687]
 [0.17008911]
 [0.17035247]
 [0.16987969]
 [0.17058931]
 [0.17018223]
 [0.16968526]
 [0.16996571]
 [0.17040544]
 [0.17047735]
 [0.17010327]
 [0.17088706]
 [0.170406  ]
 [0.17026727]
 [0.16978516]
 [0.16990977]]
wv_jc shape (30,)
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
wv_ndT shape (30,)
[0.71893524 0.6819206  0.63907898 0.66945874 0.60884419 0.
 0.         0.12586633 1.         1.         1.         0.
 0.96867626 0.         0.         0.04440604 1.         1.
 1.         0.         1.         0.         0.03216351 1.
 0.06618415 0.         0.1837188  0.         0.         1.        ]
wv_std shape (30,)
[0.         0.         0.         0.         0.         0.84737846
 0.         0.39685894 1.         0.91382275 1.         0.
 0.82164262 0.81263865 1.         1.         1.         0.26267188
 1.         1.         1.         1.         1.         1.
 1.         1.         1.         0.82164063 1.         1.        ]
xy shape: (30, 9)
[[0.         0.         0.         0.         0.16900213 1.
  0.71893524 0.         0.        ]
 [0.         0.         0.         0.         0.16900828 1.
  0.6819206  0.         0.        ]
 [0.         0.         0.         0.         0.1690347  1.
  0.63907898 0.         0.        ]
 [0.         0.         0.         0.         0.16901142 1.
  0.66945874 0.         0.        ]
 [0.         0.         0.         0.         0.16900423 1.
  0.60884419 0.         0.        ]
 [0.         0.         0.5624967  0.81852996 0.1703377  1.
  0.         0.84737846 1.        ]
 [0.         0.         0.         0.50679675 0.17035423 1.
  0.         0.         1.        ]
 [0.         0.         1.         1.         0.17012207 1.
  0.12586633 0.39685894 1.        ]
 [0.         0.         1.         1.         0.17038202 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.16993681 1.
  1.         0.91382275 1.        ]
 [0.         0.         0.63856481 0.91687508 0.17024851 1.
  1.         1.         1.        ]
 [0.         1.         0.64614247 1.         0.1693318  1.
  0.         0.         1.        ]
 [1.         0.         1.         1.         0.17009064 1.
  0.96867626 0.82164262 1.        ]
 [0.         0.         1.         1.         0.17044566 1.
  0.         0.81263865 1.        ]
 [1.         0.         1.         1.         0.16979687 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.17008911 1.
  0.04440604 1.         1.        ]
 [1.         0.         1.         1.         0.17035247 1.
  1.         1.         1.        ]
 [0.         0.         0.70976709 1.         0.16987969 1.
  1.         0.26267188 1.        ]
 [0.         0.         1.         1.         0.17058931 1.
  1.         1.         1.        ]
 [0.         0.         0.44210024 1.         0.17018223 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.16968526 1.
  1.         1.         1.        ]
 [0.         0.         1.         1.         0.16996571 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.17040544 1.
  0.03216351 1.         1.        ]
 [0.         0.         1.         1.         0.17047735 1.
  1.         1.         1.        ]
 [1.         0.         1.         1.         0.17010327 1.
  0.06618415 1.         1.        ]
 [0.         1.         0.         0.         0.17088706 1.
  0.         1.         1.        ]
 [0.         0.         1.         1.         0.170406   1.
  0.1837188  1.         1.        ]
 [0.         0.         0.55872757 1.         0.17026727 1.
  0.         0.82164063 1.        ]
 [0.0897935  0.         1.         1.         0.16978516 1.
  0.         1.         1.        ]
 [0.41284321 0.         1.         1.         0.16990977 1.
  1.         1.         1.        ]]

Best Training Poisoning Accuracy:
0.7142857313156128
#####################         POISON         ###############################################

############################################################################################

comm_round: 0 | global_test_acc: 100.000% | global_f1: 1.0 | global_precision: 1.0
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        10

    accuracy                           1.00        10
   macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10

Accuracy per class:
[[10  0]
 [ 0  0]]
[ 1. nan]
poison scaling shape: (30, 1)
[[1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]
 [1]]scaled_weight_list: Rows 30 cols 21Adding node: 0 value: [1] to honest_clientsAdding node: 1 value: [1] to honest_clientsAdding node: 2 value: [1] to honest_clientsAdding node: 3 value: [1] to honest_clientsAdding node: 4 value: [1] to honest_clientsAdding node: 5 value: [1] to honest_clientsAdding node: 6 value: [1] to honest_clientsAdding node: 7 value: [1] to honest_clientsAdding node: 8 value: [1] to honest_clientsAdding node: 9 value: [1] to honest_clientsAdding node: 10 value: [1] to honest_clientsAdding node: 11 value: [1] to honest_clientsAdding node: 12 value: [1] to honest_clientsAdding node: 13 value: [1] to honest_clientsAdding node: 14 value: [1] to honest_clientsAdding node: 15 value: [1] to honest_clientsAdding node: 16 value: [1] to honest_clientsAdding node: 17 value: [1] to honest_clientsAdding node: 18 value: [1] to honest_clientsAdding node: 19 value: [1] to honest_clientsAdding node: 20 value: [1] to honest_clientsAdding node: 21 value: [1] to honest_clientsAdding node: 22 value: [1] to honest_clientsAdding node: 23 value: [1] to honest_clientsAdding node: 24 value: [1] to honest_clientsAdding node: 25 value: [1] to honest_clientsAdding node: 26 value: [1] to honest_clientsAdding node: 27 value: [1] to honest_clientsAdding node: 28 value: [1] to honest_clientsAdding node: 29 value: [1] to honest_clients